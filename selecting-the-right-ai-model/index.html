<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-selecting-the-right-ai-model" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Selecting the Right AI Model | White Paper</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://lkgarcia.github.io/whitepaper/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://lkgarcia.github.io/whitepaper/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://lkgarcia.github.io/whitepaper/selecting-the-right-ai-model"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Selecting the Right AI Model | White Paper"><meta data-rh="true" name="description" content="Executive Summary"><meta data-rh="true" property="og:description" content="Executive Summary"><link data-rh="true" rel="icon" href="/whitepaper/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://lkgarcia.github.io/whitepaper/selecting-the-right-ai-model"><link data-rh="true" rel="alternate" href="https://lkgarcia.github.io/whitepaper/selecting-the-right-ai-model" hreflang="en"><link data-rh="true" rel="alternate" href="https://lkgarcia.github.io/whitepaper/selecting-the-right-ai-model" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Agentic AI in Banking","item":"https://lkgarcia.github.io/whitepaper/"},{"@type":"ListItem","position":2,"name":"Selecting the Right AI Model","item":"https://lkgarcia.github.io/whitepaper/selecting-the-right-ai-model"}]}</script><link rel="alternate" type="application/rss+xml" href="/whitepaper/blog/rss.xml" title="White Paper RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/whitepaper/blog/atom.xml" title="White Paper Atom Feed"><link rel="stylesheet" href="/whitepaper/assets/css/styles.15159f72.css">
<script src="/whitepaper/assets/js/runtime~main.a8b0c4f6.js" defer="defer"></script>
<script src="/whitepaper/assets/js/main.f4efcb85.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/whitepaper/"><b class="navbar__title text--truncate">WHITE PAPER</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/whitepaper/"><span title="Agentic AI in Banking" class="categoryLinkLabel_W154">Agentic AI in Banking</span></a><button aria-label="Collapse sidebar category &#x27;Agentic AI in Banking&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whitepaper/banking-reimagined-through-agentic-ai"><span title="Banking Reimagined Through Agentic AI" class="linkLabel_WmDU">Banking Reimagined Through Agentic AI</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whitepaper/balancing-autonomy-and-agency"><span title="Balancing Autonomy and Agency" class="linkLabel_WmDU">Balancing Autonomy and Agency</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whitepaper/the-ai-use-case-canvas"><span title="The AI Use Case Canvas" class="linkLabel_WmDU">The AI Use Case Canvas</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whitepaper/enabling-agentic-ai-through-well-defined-api-contracts"><span title="Enabling Agentic AI Through Well-Defined API Contracts" class="linkLabel_WmDU">Enabling Agentic AI Through Well-Defined API Contracts</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/whitepaper/selecting-the-right-ai-model"><span title="Selecting the Right AI Model" class="linkLabel_WmDU">Selecting the Right AI Model</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whitepaper/high-impact-use-cases"><span title="High-Impact Use Cases and Strategic Insights" class="linkLabel_WmDU">High-Impact Use Cases and Strategic Insights</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whitepaper/building-enterprise-ai-agents"><span title="Building Enterprise AI Agents" class="linkLabel_WmDU">Building Enterprise AI Agents</span></a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/whitepaper/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/whitepaper/"><span>Agentic AI in Banking</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Selecting the Right AI Model</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>WORK IN PROGRESS</div></div>
<header><h1>Selecting the Right AI Model: A Framework for Reliable and Scalable Agentic Systems</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="executive-summary">Executive Summary<a href="#executive-summary" class="hash-link" aria-label="Direct link to Executive Summary" title="Direct link to Executive Summary" translate="no">​</a></h2>
<p>Agentic AI systems in retail banking promise personalized guidance, smarter fraud detection, and improved customer service. Yet choosing the <em>right</em> AI models and adaptation strategies is critical to balance capability with cost, speed, and risk. This paper presents a structured decision framework for model selection. We define a taxonomy of model scales – from Large Language Models (LLMs) to Small Language Models (SLMs) and narrow domain models – and outline criteria for when to use each. We compare prompt engineering versus Retrieval-Augmented Generation (RAG) versus fine-tuning, and discuss emerging multi-modal AI (combining text with images or other inputs). We quantify the often-underestimated costs of fine-tuning (data collection, annotation, infrastructure) and highlight evaluation dimensions like accuracy, latency, hallucination rates, and compliance. Finally, we provide a phased roadmap for adopting and evolving an optimal model portfolio. By following a disciplined selection approach, banking innovators can deploy AI agents that are <strong>reliable, scalable, and cost-effective</strong> – avoiding the pitfalls that cause many AI projects to stall1.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>As generative AI moves past the initial hype, banks face pressure to deliver value while controlling costs and risks. Recent surveys predict <strong>at least 30% of enterprise GenAI projects will be abandoned by 2025</strong> due to poor data quality, inadequate risk controls, escalating costs or unclear ROI1. In retail banking – where accuracy and compliance are paramount – blindly deploying the largest model is no longer tenable. <strong>Cost has become as big an AI risk as security or hallucinations</strong>, according to Gartner2. Meanwhile, regulators and customers demand reliable, explainable outcomes. In this context, <em>model selection</em> is not just a technical decision but a strategic one. Choosing an appropriate model (or combination) can mean the difference between an AI assistant that safely streamlines operations versus one that overruns budget or misleads users. This paper argues that a disciplined framework for model selection and adaptation is now essential. By systematically aligning use cases with the right model scale and approach, banks can achieve strong AI capabilities <strong>while maintaining control over latency, cost, and governance</strong>.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="technical-fundamentals">Technical Fundamentals<a href="#technical-fundamentals" class="hash-link" aria-label="Direct link to Technical Fundamentals" title="Direct link to Technical Fundamentals" translate="no">​</a></h2>
<p><strong>Model Scale vs. Capability vs. Latency:</strong> Modern language models range from billions to hundreds of billions of parameters. Generally, <strong>larger models demonstrate broader knowledge and more sophisticated reasoning, but with higher cost and slower responses</strong>. For example, a 70B-parameter model might answer complex queries more accurately than a 7B model, but will incur significantly more latency and expense per query. In one benchmark, moving from a 1B to a 70B model increased inference latency roughly 10× (0.2s to 3s for the same output length) and <em>per-token costs by over 7×</em> under comparable conditions<a href="https://openreview.net/pdf?id=pZFJLsIY2m#:~:text=restricts%20real,1" target="_blank" rel="noopener noreferrer" class="">openreview.net</a>. In other words, scale brings diminishing returns: accuracy does not increase linearly with size3. Smaller models (e.g. 1–15B parameters) can often match larger models on narrow or structured tasks when fine-tuned, and they can deliver responses in tens of milliseconds instead of seconds3. The trade-off is clear – <strong>bigger isn’t always better</strong>; the optimal size depends on task complexity and real-time requirements. Key performance metrics to monitor include time-to-first-token (how quickly the model starts responding), throughput (requests per second it can handle), and memory/compute footprint.</p>
<p><strong>Adaptation Continuum:</strong> Beyond choosing a base model, architects must decide how to <em>adapt</em> it to the task. Approaches fall along a continuum of effort and flexibility:</p>
<ul>
<li class="">
<p><strong>Prompt Engineering (Context-Only):</strong> Using carefully crafted prompts, system instructions, and examples to guide a general model’s behavior without changing its weights. This is the fastest to implement – requiring no model training – and works well when a powerful LLM can solve the task with general knowledge and a bit of guidance. However, prompt-only solutions may struggle with highly domain-specific queries or factual accuracy on enterprise data.</p>
</li>
<li class="">
<p><strong>Retrieval-Augmented Generation (RAG):</strong> Here the model remains frozen, but is supplied with relevant <em>external context</em> at query time (typically via a vector database lookup). RAG allows systems to <strong>inject up-to-date, domain-specific information into the model’s context</strong>, mitigating the model’s knowledge cutoff or limited training data. This can greatly improve factual accuracy and reduce hallucinations4. The trade-off is added complexity: one must maintain a knowledge repository and ensure the retriever finds high-quality context. RAG introduces latency from the retrieval step, but pipelines can be optimized to still meet interactive speeds. Crucially, RAG <strong>improves transparency and verifiability</strong>, since the model’s answers are grounded in retrieved evidence<a href="https://www.mdpi.com/2504-4990/6/4/116#:~:text=Our%20approach%20leverages%20the%20inherent,possible%2C%20especially%20in%20scenarios%20where" target="_blank" rel="noopener noreferrer" class="">mdpi.com</a><a href="https://www.mdpi.com/2504-4990/6/4/116#:~:text=technique%20used%20for%20enhancing%20the,then%20encoded%20into%20a%20vectorised" target="_blank" rel="noopener noreferrer" class="">mdpi.com</a>.</p>
</li>
<li class="">
<p><strong>Fine-Tuning (Domain Adaptation):</strong> Fine-tuning entails training the model on domain-specific examples or instructions so that it <em>internalizes</em> task knowledge. This can yield strong performance on specialized tasks and reduce the need for elaborate prompts at runtime. Techniques range from full model fine-tuning to parameter-efficient methods (e.g. low-rank adapters or LoRA). Fine-tuning an LLM, however, is a non-trivial project – it requires assembling quality training data, running experiments on GPUs, and evaluating carefully. <strong>The costs can be significant</strong>, both in one-time training spend and ongoing maintenance as data or requirements change. We discuss these costs in depth later. Fine-tuning is best reserved for scenarios where high accuracy on a well-defined task justifies the investment, or where data privacy requires an on-prem model that “knows” internal data without retrieval.</p>
</li>
<li class="">
<p><strong>Multi-Modal Integration:</strong> Many banking use cases involve not just text but documents, forms, images of IDs or checks, audio from calls, etc. Multi-modal models extend language models with vision, speech, or structured data capabilities. For example, a multi-modal AI assistant might analyze a photo of a handwritten check along with a customer’s query. Such models are emerging rapidly – Gartner projects **40% of GenAI solutions will be multimodal by 2027 (up from just 1% in 2023)**5. Adopting multi-modality can unlock richer functionality (e.g. reading financial statements or parsing transaction receipts), but also raises complexity in model selection and deployment. Often it involves combining separate specialized models (which can introduce latency and integration challenges) or using a very large model natively trained on mixed data. We must consider whether multi-modal capability is essential for a given use case, or if simpler pipelines (like extracting text from documents then using an LLM) suffice in the near term.</p>
</li>
</ul>
<p><strong>Evaluation and Risk Axes:</strong> When evaluating model options, it is critical to go beyond raw accuracy on paper. A holistic evaluation should encompass multiple axes6:</p>
<ul>
<li class="">
<p><strong>Accuracy &amp; Relevance:</strong> Does the model output correct and useful answers for the task? This includes factual accuracy for knowledge queries and numerical accuracy for calculations.</p>
</li>
<li class="">
<p><strong>Hallucination Rate:</strong> How often does the model “make up” an answer? Hallucination is especially concerning in finance (e.g. fabricating a regulatory requirement or a transaction that never occurred). Techniques like RAG and prompt constraints help here, but measurement is key – e.g. track the percentage of responses containing unverifiable claims.</p>
</li>
<li class="">
<p><strong>Latency:</strong> Response time under expected load. An otherwise accurate model that takes 10 seconds per query may fail in a live chat context. Set targets (e.g. &lt; 2 seconds for customer-facing agents) and test with realistic concurrent usage.</p>
</li>
<li class="">
<p><strong>Cost per Query:</strong> Roughly, the compute or API expense per 1000 tokens for each model. This can vary by an order of magnitude between model choices (as shown in the earlier example of 1B vs 70B token pricing<a href="https://openreview.net/pdf?id=pZFJLsIY2m#:~:text=restricts%20real,1" target="_blank" rel="noopener noreferrer" class="">openreview.net</a>). Estimating cost at scale prevents sticker shock once deployed.</p>
</li>
<li class="">
<p><strong>Privacy and Compliance:</strong> Does using the model introduce data residency or privacy concerns? Smaller on-prem models give more control, whereas third-party LLM APIs might send sensitive data off-site (needing encryption or redaction). Also, assess if the model has mechanisms for auditing its outputs or explaining decisions – important for compliance.</p>
</li>
<li class="">
<p><strong>Robustness and Bias:</strong> How does the model perform on edge cases or biased inputs? Are there guardrails to prevent toxic or biased outputs? Evaluation should include stress-testing for unacceptable outputs, especially given fairness and ethical expectations in banking.</p>
</li>
<li class="">
<p><strong>Operational Maturity:</strong> Consider the tooling and community support for the model. Mature models have better monitoring, debuggability, and fine-tuning support. An open-source model might allow internal audit of its weights, whereas a closed API might offer built-in monitoring tools. Ensure you can log interactions and retrain or update the model over time (for example, to handle model drift as language or products evolve).</p>
</li>
</ul>
<p>By scoring options across these dimensions, decision-makers can surface trade-offs clearly – for instance, Model A might score highest on accuracy but pose greater compliance overhead, whereas Model B is slightly less accurate but far cheaper and faster.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="deep-dive-topics">Deep Dive Topics<a href="#deep-dive-topics" class="hash-link" aria-label="Direct link to Deep Dive Topics" title="Direct link to Deep Dive Topics" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="taxonomy-of-model-options-llm-vs-slm-vs-nlm">Taxonomy of Model Options: LLM vs SLM vs NLM<a href="#taxonomy-of-model-options-llm-vs-slm-vs-nlm" class="hash-link" aria-label="Direct link to Taxonomy of Model Options: LLM vs SLM vs NLM" title="Direct link to Taxonomy of Model Options: LLM vs SLM vs NLM" translate="no">​</a></h3>
<p>Not all “AI models” are created equal. It’s useful to classify the types of models available:</p>
<ul>
<li class="">
<p><strong>Large Language Models (LLMs):</strong> These are the big generalists – typically with <strong>tens or hundreds of billions of parameters, trained on massive text corpora</strong>. Examples include GPT-4-class models or PaLM. LLMs excel at open-ended understanding and reasoning. They can follow complex instructions and have extensive world knowledge. For a bank, an LLM could answer a wide range of customer questions or draft detailed reports with minimal task-specific training. However, they come with <strong>significant drawbacks in enterprise settings</strong>: high inference costs, increased latency, and often they run only via cloud APIs (raising data governance concerns). Fine-tuning an LLM on proprietary data is also expensive (often requiring specialist hardware and weeks of effort). As one recent survey noted, LLMs face <em>“high fine-tuning costs, inference latency, limited edge deployability, and reliability concerns”</em> despite their impressive capabilities3. Thus, LLMs are powerful but heavy tools – best reserved for when the use case truly demands top-tier language prowess across broad knowledge.</p>
</li>
<li class="">
<p><strong>Small/Medium Language Models (SLMs):</strong> There is no hard cutoff, but SLMs typically range from ~100 million up to 6–15 billion parameters. These models are <strong>orders of magnitude more efficient</strong>, often able to run on a single GPU or even CPU with sub-second latency3. Examples include distilled versions of larger models or bespoke smaller architectures. While an SLM may not match an LLM on complex reasoning out-of-the-box, it can perform remarkably well on domain-specific tasks <strong>when fine-tuned or provided relevant context</strong>. In fact, SLMs fine-tuned on a focused dataset can rival or outperform far larger models on that niche (for example, a 7B model fine-tuned on banking FAQs might beat a 70B model that has never seen those). Enterprise teams favor SLMs for <strong>greater control and cost savings</strong>: these models can often be deployed on-premises (addressing data privacy), updated more frequently, and scaled to millions of queries economically. One industry analysis estimates that training cutting-edge LLMs costs over $100M, and even inference pricing from vendors grows steeply with model size, whereas using SLMs can <em>cut cost-per-query by two orders of magnitude</em> in production3. In short, SLMs trade some generality for <strong>speed, affordability, and ease of governance</strong>, which is often a smart trade-off for well-understood banking applications.</p>
</li>
<li class="">
<p><strong>Narrow or Specialized Models (NLMs):</strong> We use this term to denote models that are <strong>purpose-built for a specific domain or task</strong>. A narrow model could be an LLM or an SLM – size is secondary to specialization. For example, a 20B-parameter model trained exclusively on financial texts, or a refined version of a general model tuned for credit risk assessment, would qualify as a narrow model. These often originate from fine-tuning an existing model on domain data (e.g. tuning an open-source base on a bank’s documents) or from training a model from scratch on targeted data. The strength of NLMs is <strong>precision and relevance</strong>: by focusing on a limited scope, they can achieve high accuracy and use terminology correctly (reducing irrelevant or incorrect outputs for that domain). NLMs also tend to be more efficient for their domain, since they aren’t burdened by knowledge of unrelated topics. The downside is brittleness outside their specialty – a narrow model might fail if asked something slightly out-of-distribution. In practice, many enterprise AI solutions compose multiple narrow models, each tackling a piece of the problem (for example, one model classifies transaction anomalies while another generates customer responses). When we refer to NLMs, think <em>“small or large, but specifically fine-tuned for our needs.”</em> These require effort to build and maintain but can deliver superior results for high-value tasks like fraud detection, where general models may not be as reliable on the nuances.</p>
</li>
</ul>
<p>It is worth noting that these categories overlap. A given solution might use an LLM for general reasoning but an SLM for a particular tool-like function. Also, <strong>open-source vs. closed-source</strong> is another consideration orthogonal to size: open models (often SLMs) allow more customization and on-site deployment, whereas API models (often LLMs) might offer cutting-edge performance but with vendor dependency. Organizations should inventory their use cases and identify which category (or combination) fits each scenario – rather than defaulting to one model for all.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="choosing-an-adaptation-strategy-prompting-vs-rag-vs-fine-tuning">Choosing an Adaptation Strategy: Prompting vs RAG vs Fine-Tuning<a href="#choosing-an-adaptation-strategy-prompting-vs-rag-vs-fine-tuning" class="hash-link" aria-label="Direct link to Choosing an Adaptation Strategy: Prompting vs RAG vs Fine-Tuning" title="Direct link to Choosing an Adaptation Strategy: Prompting vs RAG vs Fine-Tuning" translate="no">​</a></h3>
<p>Selecting the base model is step one; next comes deciding how that model will incorporate domain knowledge and stay current. We compare three prevalent strategies:</p>
<ul>
<li class="">
<p><strong>LLM + System Prompt Only:</strong> <em>When to use:</em> If your use case is relatively general (e.g. conversational FAQs, common-sense reasoning) and doesn’t require up-to-the-minute data, you might simply use a strong LLM out-of-the-box. With thoughtful system prompts and maybe a few examples, the model can often handle tasks via zero-shot or few-shot learning. This approach shines for prototypes or when you need to support a wide variety of queries without building a custom pipeline. It minimizes initial effort – no model training needed – but <strong>watch out for hallucinations or knowledge gaps</strong>. For instance, asking a raw LLM about your bank’s latest policies could yield confident <em>but incorrect</em> answers. This strategy also struggles if the model must reliably cite sources or process customer-specific data (like account info). Use prompt-only when the convenience outweighs the risk, and implement guardrails (like pattern-based checks or fallbacks) to handle when the model’s response might be off the mark.</p>
</li>
<li class="">
<p><strong>Retrieval-Augmented Generation (RAG):</strong> <em>When to use:</em> If the task requires <strong>incorporating proprietary or dynamic information</strong> (e.g. a virtual assistant giving personalized financial advice using a customer’s transaction history, or an AI tool that answers questions about internal banking procedures), RAG is a compelling approach. Rather than trying to encode all that knowledge in the model’s weights via fine-tuning, RAG keeps a <strong>searchable knowledge base</strong> (documents, database entries, etc.). At query time, the system retrieves relevant snippets and prepends them to the model’s prompt. The LLM or SLM then generates an answer <em>grounded in those snippets</em>. The benefit is two-fold: your AI’s knowledge is easily updatable (just add or edit documents in the knowledge store) and <strong>factual accuracy improves</strong>, since the model has the sources in front of it. Studies show retrieval can significantly cut down hallucination rates – one analysis found integrating retrieval reduced incorrect statements by 42–68% in tested scenarios4. Moreover, users and auditors can often trace the answer back to a source document, aiding explainability. The downsides include the engineering overhead of maintaining the retrieval system and ensuring data coverage. Also, if the retrieval fails (no relevant document found), the model might still stumble. RAG is ideal when <strong>your domain data is extensive and changes frequently</strong> (e.g. compliance rules, product details) or when answers must cite evidence. Many high-impact banking uses (fraud investigation assistants, research tools for analysts, customer support bots connected to knowledge bases) will benefit from a RAG architecture.</p>
</li>
<li class="">
<p><strong>Fine-Tuning the Model:</strong> <em>When to use:</em> If the use case is <em>narrowly defined, high-volume, and critical for accuracy</em>, and you have quality training data (or can create it), fine-tuning can pay off. Fine-tuning means your model effectively <em>learns</em> the task – for example, classifying loan applications as approved/denied based on historical data, or generating tailored marketing messages in the brand tone. This often yields the <strong>best task performance</strong> because the model parameters are optimized for your specific data. Fine-tuning is also the go-to when the model needs to handle <em>nuanced outputs or formats</em> (like generating SQL queries or regulatory reports) that are hard to reliably get via prompting alone. However, the commitment is substantial: one must gather and label data, invest in training runs, evaluate on validation sets, and possibly repeat this process to adjust to drift (e.g. new regulatory changes requiring model update). <strong>Data availability is usually the deciding factor</strong> – if you don’t have a large, representative dataset for the task, fine-tuning a big model is ill-advised. In such cases, prompt-based or retrieval approaches are safer. Additionally, fine-tuning large models can be very costly and slow (even with techniques like parameter-efficient tuning). An emerging best practice is to fine-tune smaller open-source models for specific tasks, while using a large model for general reasoning or as a fallback. This “hybrid” approach can give the best of both: the fine-tuned NLM for what it’s great at, and an LLM for everything else. We’ll discuss cost considerations next – in short, <strong>fine-tuning is an investment</strong> that should be justified by a clear business case (e.g. expected improvement in accuracy or user experience that outweighs the effort).</p>
</li>
</ul>
<p>Finally, note that these strategies aren’t mutually exclusive. For instance, you might fine-tune a model and <em>also</em> use retrieval augmentation with it to inject new facts. Or use prompting and RAG together with an LLM. The art of solution design is picking the minimal complexity approach that meets the requirements. A decision flow diagram can help choose a path (see <strong>Figure 1</strong>).</p>
<!-- -->
<p><em>Figure 1: Decision flow for model selection.</em> From top, assess if the problem is domain-specific and whether you have data to fine-tune a custom model. If not, use retrieval to inject domain knowledge into a general model. For general-use cases, decide based on task complexity: simple tasks with tight speed/cost budgets favor smaller models, whereas complex reasoning might require a large model. In all cases, if the use case involves non-text data (e.g. document images), consider a multi-modal extension.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="cost-and-effort-of-fine-tuning">Cost and Effort of Fine-Tuning<a href="#cost-and-effort-of-fine-tuning" class="hash-link" aria-label="Direct link to Cost and Effort of Fine-Tuning" title="Direct link to Cost and Effort of Fine-Tuning" translate="no">​</a></h3>
<p>Fine-tuning deserves a closer look because its costs are often <em>underestimated</em>. It’s tempting to assume we can just train the model on our data and achieve a magic boost in accuracy. In reality, successful fine-tuning in an enterprise setting entails:</p>
<ul>
<li class="">
<p><strong>Data Collection and Labeling:</strong> Obtaining a high-quality dataset of task examples is usually the hardest part. In retail banking, this might mean months of historical chat transcripts annotated with correct responses, or thousands of transaction records labeled as fraudulent or not. The labor (often involving domain experts) to create these labels can be very expensive – recent analyses indicate that the <strong>human annotation cost now often exceeds the computational cost of training</strong> large models7. For example, one study found that for state-of-the-art models in 2024, the total spend on human-provided fine-tuning data was about <em>3× the spend on compute hardware</em> for training those models7. This trend is only growing as model training becomes more efficient but quality data remains scarce. In short, be prepared to invest in data as a first-class cost.</p>
</li>
<li class="">
<p><strong>Compute Infrastructure:</strong> Fine-tuning large models requires robust infrastructure (GPUs or TPUs) and MLOps pipelines. Even with cloud offerings, the <strong>training fees can rack up quickly</strong>. As a ballpark, fine-tuning a 10B+ parameter model on a moderately sized dataset could cost tens of thousands of dollars in cloud compute, not including iteration if you need to experiment with hyperparameters. Smaller models or parameter-efficient methods (like using LoRA adapters or low-bit quantization) can significantly cut this cost, and are recommended unless full model tuning is absolutely necessary. Also consider <em>opportunity cost</em>: engineering time to set up and manage these jobs.</p>
</li>
<li class="">
<p><strong>Evaluation and Validation:</strong> You cannot just fine-tune and deploy blindly, especially in a regulated domain. You need held-out test data and possibly a human evaluation process to ensure the tuned model performs as expected and hasn’t overfit or picked up new biases. This step might involve additional annotation (for test sets or for evaluating outputs for things like bias or compliance issues). Plan time for a rigorous evaluation cycle, including adversarial testing (e.g. does a fine-tuned chatbot hallucinate less, or perhaps more confidently now? Has it forgotten how to handle inputs outside the fine-tuned domain?).</p>
</li>
<li class="">
<p><strong>Deployment and Monitoring:</strong> Once a fine-tuned model is in production, monitoring is crucial to catch drift or performance regressions. If the model starts making errors as data trends shift (say, new types of fraud emerge), you need a process to collect new data and re-train or fine-tune again. This ongoing maintenance can be significant. Think of a fine-tuned model as a new <em>software asset</em> that requires lifecycle management: versioning, change audits, periodic retraining, etc., especially as <strong>regulations or product definitions change over time</strong>.</p>
</li>
<li class="">
<p><strong>Risk Mitigation:</strong> Fine-tuning can inadvertently introduce or amplify biases present in the fine-tuning data, or cause the model to become too confident in a narrow area. It may also leak proprietary data if not done carefully (for instance, if internal data is used to fine-tune a model that is then publicly accessible). Governance steps like data anonymization, bias checks, and security reviews of the model are advisable. Unlike prompting or retrieval, where the base model remains unchanged (and often well-tested), a fine-tuned model is unique – its failures are your responsibility. This is manageable with proper processes but is a heavier lift in terms of accountability.</p>
</li>
</ul>
<p>When do these costs and efforts become “worth it”? One rule of thumb is to fine-tune only if the expected scale of use and required accuracy of the task will provide a strong return on that investment. For example, if automating a certain decision via a fine-tuned model could save millions of dollars or significantly reduce manual work, and no off-the-shelf model can do it, the investment is justified. Another case is if fine-tuning a smaller open model can drastically reduce reliance on an expensive API model – the breakeven might come after a certain number of queries served. <strong>Banks should quantify these trade-offs</strong>. In some cases, starting with a prompt/RAG approach to validate impact, then upgrading to a fine-tuned model for efficiency at scale, can be a pragmatic path.</p>
<p>It’s also worth noting new techniques that reduce fine-tuning effort: <em>few-shot fine-tuning</em> (using relatively few examples combined with clever prompting), <em>reward model tuning</em> (RLHF) to align outputs, and <em>modular training</em> (like adding a small domain expert model that works alongside the general model). These can lower data or compute requirements. But whichever approach, always include the costs of data, people, and long-term maintenance in your project planning – not just the one-time training bill.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="multi-modal-models-in-retail-banking">Multi-Modal Models in Retail Banking<a href="#multi-modal-models-in-retail-banking" class="hash-link" aria-label="Direct link to Multi-Modal Models in Retail Banking" title="Direct link to Multi-Modal Models in Retail Banking" translate="no">​</a></h3>
<p>Many transformative banking AI use cases go beyond text. Consider a fraud investigation agent that reviews scanned ID documents and transaction logs, or a virtual financial advisor that can interpret charts and PDFs in addition to chat. Multi-modal AI refers to systems that can process and combine text, images, audio, and even other data like tables.</p>
<p>Today, there are early examples: OCR (optical character recognition) models to read documents, vision-language models (like document question-answering systems) that can take a document image and a query about it, etc. For retail banking, <strong>document understanding is a key area</strong> – from KYC verification documents to bank statements, a lot of information is locked in PDFs or images. Multi-modal models could automatically extract insights from a pile of paperwork or help a customer understand a chart from their spending history.</p>
<p>However, integrating multi-modal capabilities comes with constraints:</p>
<ul>
<li class="">
<p>Multi-modal models (like those combining vision and language) are often large and still experimental. If you need a model that reads images and responds in text, you might be looking at very new research systems (with correspondingly uncertain behavior).</p>
</li>
<li class="">
<p>An alternative is a pipeline: use a dedicated tool for the non-text part (e.g. an OCR engine or an image classifier) and then feed the results into a language model. This can work well (and is currently a common approach) but requires orchestration and can suffer from <em>latency</em> or <em>error propagation</em> between stages.</p>
</li>
<li class="">
<p>There’s also the question of <strong>data</strong> – training a truly integrated multi-modal model for your domain might not be feasible if you don’t have a large corpus of paired image-text data (e.g. thousands of annotated loan application forms). Using a pre-trained multimodal foundation model is possible, but those are typically very large (and often closed-source).</p>
</li>
<li class="">
<p><strong>Regulatory clarity</strong> on multi-modal outputs is evolving. For instance, if an AI analyses an image of an official ID, what audit trail is needed? Ensuring the visual data is handled with the same care as text data is important (e.g. no retention of images beyond their use, proper encryption, etc.).</p>
</li>
</ul>
<p>Given these factors, the emerging recommendation for most in 2025 is to <strong>start leveraging multi-modal AI in a cautious, incremental way</strong>. You might begin by connecting a vision API to an LLM in a limited scope pilot – for example, allow a chatbot to retrieve a relevant figure from a chart image by calling an external vision service. Monitor the value and issues. Over the longer term (next 2–3 years), expect multi-modal foundation models to become more accessible and enterprise-friendly, at which point adopting one platform that natively handles text + documents could yield big advantages (Gartner analysts forecast a rapid rise in such use within five years5). The key is to ensure your architecture is <strong>modular</strong> enough that you can plug in these capabilities when ready – e.g. design your agent to call specialized modules for vision or speech when needed, rather than assuming all input is plain text.</p>
<p>In retail banking specifically, likely early wins for multi-modality will be:</p>
<ul>
<li class="">
<p><strong>Document ingestion and Q&amp;A:</strong> e.g. an agent that reads a PDF policy document and answers questions about it (combining document OCR and an LLM).</p>
</li>
<li class="">
<p><strong>Receipt or Invoice Processing:</strong> a system that takes images of receipts or invoices and automatically categorizes expenses or flags discrepancies (useful for personal finance management tools).</p>
</li>
<li class="">
<p><strong>Visual Fraud Signals:</strong> analyzing things like screenshot evidence of phishing or fake IDs – here a model might need to see an image and describe issues or inconsistencies.</p>
</li>
<li class="">
<p><strong>Voice-enabled assistants:</strong> integrating speech-to-text for voice banking assistants, though that’s more about modality input/output than model internals (and can often be handled by separate ASR (automatic speech recognition) feeding a language model).</p>
</li>
</ul>
<p>Each of these can be approached with a combination of narrow models (for the vision or speech part) and language models. The long-term vision is a unified agent that seamlessly handles any modality. Banks should track progress but not rush to adopt multi-modal models until they are sufficiently robust for the given task, due to the added complexity.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="cost-optimization-techniques">Cost Optimization Techniques<a href="#cost-optimization-techniques" class="hash-link" aria-label="Direct link to Cost Optimization Techniques" title="Direct link to Cost Optimization Techniques" translate="no">​</a></h3>
<p>Optimizing cost is not just about picking a cheaper model; it’s an ongoing discipline in agentic system design. Some tactics to consider:</p>
<ul>
<li class="">
<p><strong>Right-sizing the Model:</strong> Don’t use a 175B-parameter model if a 7B model suffices for 95% of queries. Use evaluation to determine the smallest model that meets your accuracy requirements. Often, fine-tuning or RAG can allow use of a smaller base model. Also explore distillation – large models’ knowledge can sometimes be distilled into smaller models for deployment, retaining much of the performance at a fraction of the runtime cost.</p>
</li>
<li class="">
<p><strong>Dynamic Model Routing:</strong> For heterogeneous workloads, you can route requests to different models based on complexity. For example, simple or routine questions go to a small, fast model, whereas only the tricky ones get escalated to a big LLM. Early research prototypes show that such smart routing can dramatically cut average cost while maintaining quality<a href="https://openreview.net/pdf?id=pZFJLsIY2m#:~:text=integrate%20multiple%20components%2C%20often%20LLMs,2%20Instruct%20%281B" target="_blank" rel="noopener noreferrer" class="">openreview.net</a><a href="https://openreview.net/pdf?id=pZFJLsIY2m#:~:text=generates%20100%20tokens%20in%200,weighted%20matching%20to" target="_blank" rel="noopener noreferrer" class="">openreview.net</a>. The key is having a reliable way to predict which queries need the “power” of the large model – possibly via confidence scores or a lightweight classifier. As this technique matures, expect it to become a standard part of enterprise AI stacks (some vendors are already exploring cost-based routers).</p>
</li>
<li class="">
<p><strong>Caching and Reuse:</strong> Many queries in banking are repetitive (think: “What’s my balance?” or “How do I reset my password?”). Caching LLM responses for common queries (where privacy allows) can save cost and improve latency. Even at a finer grain, caching vector retrieval results or intermediate computations can help. Just be cautious to invalidate caches when underlying data changes (e.g. don’t cache a balance for too long). In internal agent use cases (like research assistants), you can cache aggressively since slight staleness might be acceptable.</p>
</li>
<li class="">
<p><strong>Batching and Concurrency:</strong> If using cloud API models, costs are often linear per call, so combining multiple tasks into one prompt can sometimes save money (if the API pricing is per token and you can utilize more tokens in one go). For instance, processing 10 small requests in a single batch prompt to a model might be cheaper than 10 separate calls – but this depends on the API and context window limits. For self-hosted models, increasing batch size improves throughput and amortizes overhead, up to hardware limits.</p>
</li>
<li class="">
<p><strong>Monitoring and Usage Governance:</strong> Keep an eye on usage patterns and have budgets or alerts. It’s easy for costs to creep if an agent starts being used more widely or if prompts unintentionally grow in length. One Gartner report warned that if CIOs don’t understand how GenAI costs scale, they could miscalculate budgets by 5-10×2. To avoid surprises, simulate worst-case volumes and track cost per user or per transaction as a KPI. Negotiate with vendors for volume discounts if applicable.</p>
</li>
<li class="">
<p><strong>Tiered Model Serving:</strong> Consider offering multiple tiers of service: a fast, minimal-cost option (perhaps with limited capabilities) and a premium thorough option using a larger model. For example, an automated email draft might first be generated by a local small model; only if the user requests a more polished version do you call a costly LLM. This “fallback” approach ensures you spend heavy compute only when needed. It pairs well with uncertainty detection – if the small model is unsure or produces low-confidence output, then escalate to the big model.</p>
</li>
<li class="">
<p><strong>Efficient Implementation:</strong> Low-level optimizations like quantizing model weights (using 8-bit or 4-bit precision) can greatly reduce memory and increase speed with negligible accuracy loss. This is especially valuable for self-hosted models – quantization and pruning might allow you to run an otherwise 20B model on commodity hardware. Similarly, utilize GPU inference optimizations or specialized AI hardware if you have it, to get more throughput per dollar.</p>
</li>
</ul>
<p>In summary, treat cost as a design constraint <em>just like accuracy</em>. By architecting the system with cost in mind (e.g. modular design, caching, model choice) and continuously monitoring, you can often achieve <strong>an order-of-magnitude cost reduction</strong> without significantly sacrificing quality. In banking, where margins are slim and compliance demands can inflate cost (e.g. needing on-prem solutions), these levers make the difference between a sustainable AI product and one that gets shut down for being too expensive.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="risk-and-governance-considerations">Risk and Governance Considerations<a href="#risk-and-governance-considerations" class="hash-link" aria-label="Direct link to Risk and Governance Considerations" title="Direct link to Risk and Governance Considerations" translate="no">​</a></h3>
<p>Deploying agentic AI in retail banking requires a robust risk mitigation strategy from day one. Key areas to address include:</p>
<ul>
<li class="">
<p><strong>Hallucination and Misinformation:</strong> No model is 100% free of hallucination risk. Even with RAG and fine-tuning, there will be cases where the AI produces an incorrect statement confidently. In high-stakes use (like financial advice), this is unacceptable without safeguards. Strategies to manage this include: instructing the model to say “I don’t know” or defer when unsure, building verification steps (e.g. cross-check important answers against a knowledge base or calculation), and limiting the scope of open-ended generation. Some studies have shown that combining techniques – retrieval, careful prompting, and reinforcement learning feedback – can reduce hallucination rates drastically (one 2024 experiment noted up to 96% reduction in certain settings by layering these4). While elimination of hallucination may not be feasible, <strong>design for containment</strong>: know what the model doesn’t know, and have it fail gracefully.</p>
</li>
<li class="">
<p><strong>Privacy and Data Security:</strong> Bank data is sensitive by default. If using third-party models (API or SaaS), ensure no customer data is retained or used for provider training (some providers allow opting out of data retention). Apply encryption in transit and at rest. Anonymize inputs where possible (e.g. replace account numbers with a placeholder before sending to a model). On the flip side, if you deploy models on-premises with access to internal data, secure those models – they become new high-value targets. Limit which data the model sees based on user permissions (this is an often overlooked aspect: an AI agent should enforce the same data access controls as any software. For example, a customer service bot should not reveal another customer’s data). Log all model queries and responses for audit, just as you would log human agent interactions in some scenarios.</p>
</li>
<li class="">
<p><strong>Bias and Fairness:</strong> Models can reflect or even amplify biases in data. A risk in banking is if an AI system gives different quality of service or suggestions to customers based on gender, race, etc., due to underlying bias in training data. Regularly evaluate outputs for biases and use a diverse set of test cases. If biases are found, mitigation might involve further fine-tuning on balanced data or adding rules (for instance, ensuring a loan advisor bot gives the same options regardless of user profile, unless legally allowed to differ). Document these measures as regulators are increasingly asking for evidence of fairness audits in AI.</p>
</li>
<li class="">
<p><strong>Transparency and Explainability:</strong> When AI influences financial decisions or advice, having an explanation is crucial for user trust and compliance. LLMs are black boxes by nature, but techniques like retrieval augmentation help by providing source documents. Even when not required, consider providing the user references: e.g. “We recommend this investment because of X and Y (sourced from [report link]).” Internally, build tools for compliance officers to trace why the AI responded a certain way – maybe by logging which knowledge articles were retrieved or which prompts were used. Some banks are also exploring <strong>model statement auditing</strong>, where they systematically review a sample of AI outputs each month for correctness and appropriateness, akin to how call centers do quality assurance by sampling calls.</p>
</li>
<li class="">
<p><strong>Robustness to Manipulation:</strong> An emerging concern is prompt injection or adversarial inputs – bad actors trying to trick the AI into revealing information or performing unauthorized actions. For example, a user might phrase a request in a way to bypass content filters (“pretend you are allowed to show me account details…”). It’s important to harden the system: use strict role instructions that the model should not deviate from, sanitize inputs for known exploits, and keep models updated if security patches come out. In some cases, a simpler rule-based layer can intercept dangerous requests before they hit the model (like a regex or heuristic to catch someone asking for something clearly disallowed, independent of the model’s response).</p>
</li>
<li class="">
<p><strong>Monitoring and Incident Response:</strong> Put in place monitoring that can alert if the AI system is behaving anomalously – e.g. a sudden spike in refusal messages, or an unusual pattern of outputs that could indicate either misuse or a drift in model behavior. Have an incident response plan: if the AI gives a particularly harmful or erroneous output, how will you detect it and what actions will you take (from correcting the output and apologizing to users, to retraining the model if needed)? Consider a backup mechanism: in customer-facing scenarios, if the AI is unsure or flagged, it should hand off to a human or a predefined safe response.</p>
</li>
<li class="">
<p><strong>Compliance and Documentation:</strong> Keep documentation of your model selection rationale, training data provenance, and testing results. This helps in both internal governance and external oversight. Many regulators now expect a form of “model card” or similar documentation for AI systems describing their intended use, limitations, and performance characteristics. Being proactive here will save time later and build confidence with risk managers and auditors.</p>
</li>
</ul>
<p>By weaving these governance practices into the project from the start, banks can significantly reduce the likelihood of an AI project causing compliance headaches or public relation issues. The goal is to harness the benefits of agentic AI <strong>without</strong> stumbling into the known pitfalls – many of which can be anticipated and managed with the right precautions.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="recommendations--roadmap">Recommendations &amp; Roadmap<a href="#recommendations--roadmap" class="hash-link" aria-label="Direct link to Recommendations &amp; Roadmap" title="Direct link to Recommendations &amp; Roadmap" translate="no">​</a></h2>
<p>Adopting agentic AI in a bank is a journey. We propose a three-phase roadmap to iteratively build a robust model portfolio and capability:</p>
<p><strong>Short-term (next 3–6 months):</strong> Focus on <em>experimentation and establishing guardrails</em>. Stand up an evaluation harness to benchmark different models on your key tasks (e.g. answer accuracy on a set of banking queries, latency under load tests, etc.). Start with smaller or readily available models to solve low-hanging fruits – for instance, deploy a <strong>small/medium language model with strong prompt instructions</strong> for a pilot like an FAQ chatbot, where responses are limited and can be manually verified initially. Implement basic guardrails such as content filtering and fallback to human agents for unhandled queries. The emphasis in this phase is <strong>control and understanding</strong>: get a sense of model behavior, gather feedback, and ensure you have monitoring in place. Also, this is the time to address data preparation for future steps (e.g. begin curating a knowledge base for RAG, start collecting training examples from interactions). By the end of this phase, you should have confidence in evaluating AI outputs and a clear idea of where the model meets or falls short of requirements.</p>
<p><strong>Mid-term (6–18 months):</strong> Gradually <em>increase sophistication while managing risk</em>. Based on early results, consider introducing <strong>Retrieval-Augmented Generation</strong> on a carefully curated internal knowledge base. For example, connect your chatbot or agent to a secure index of policy documents, product details, and guidelines, so it can provide up-to-date, compliant answers. This will likely improve accuracy and reduce hallucinations, but will require effort to build and govern the knowledge repository (ensure documents are approved and kept current). In parallel, identify narrow tasks that would benefit from <strong>selective fine-tuning</strong>. A good candidate might be a classification or routing task (like triaging fraud alerts or categorizing customer requests) where you have lots of labeled examples – a fine-tuned SLM could excel here and operate with low latency. Introduce such fine-tuned models as specialized components in your system (for instance, the fine-tuned model handles the classification and then hands off to an LLM for explanation). During this phase, also work on <strong>integrating evaluation into regular operations</strong>: for example, monthly metrics on accuracy and cost, and a review process for any incidents. The mid-term goal is to achieve <strong>measurable improvements in performance</strong> (more accurate answers, faster responses, reduced manual work) on key use cases, while still keeping a human in the loop for oversight on any critical decisions.</p>
<p><strong>Long-term (18+ months, ongoing):</strong> Evolve towards a <em>portfolio of models and continuous optimization</em>. By this stage, you likely have multiple AI components – perhaps a large general model, a few fine-tuned specialist models, and a retrieval system, all orchestrated. Now focus on <strong>portfolio optimization</strong>: implement dynamic routing so that each query is handled by the most efficient model that can do the job (as discussed in cost optimization). This might involve developing a meta-controller that evaluates input complexity and chooses between a fast path or a slow path. Also consider model <strong>distillation or compression</strong> efforts: if your usage of a large model is high, investigate creating a distilled version or using techniques to run it cheaper (quantization, compilers, etc.). <strong>Multi-modal expansion</strong> can also come into play – start adding capabilities for images or other data if those use cases have proven value, possibly by incorporating new foundation models that support those modalities (which by then may be more mature). Simultaneously, institutionalize the <strong>governance processes</strong>: periodic re-training to combat drift, bias audits, cost audits, and an AI governance board review for new use cases. The long-term phase is about scaling the solution in a sustainable way: more use cases onboarded, broader acceptance by staff and customers, and tight integration with business workflows. Essentially, AI agents become a normal part of operations, with a robust infrastructure ensuring they remain <strong>accurate, compliant, and cost-effective over time</strong>.</p>
<p>Throughout all phases, maintain a pragmatic outlook. The field will continue to evolve quickly – new models or techniques (perhaps better at reasoning or offering transparency) will emerge. Be ready to pilot those, but do so within the framework of your decision model: assess their true added value against the criteria of capability, cost, and risk. Avoid chasing hype; instead, let the <strong>measured improvements on your KPIs guide adoption</strong>. By following the above roadmap, an organization can steadily increase its AI sophistication while controlling risks, rather than a big-bang approach that might fail to deliver lasting value.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>In the rush to embrace AI, it’s easy to grab whatever powerful model is available and bolt it onto a problem. This paper argues for a more disciplined, framework-driven approach – especially in a sensitive domain like retail banking. <strong>Selecting the right AI model (or combination of models) is foundational to building reliable and scalable agentic systems.</strong> We’ve outlined how to break down this selection: understand the taxonomy of model types and their trade-offs, choose an adaptation strategy aligned with your data and needs, and rigorously evaluate on multiple axes beyond just accuracy.</p>
<p>By applying this framework, architects and product leaders can make evidence-based decisions instead of guesswork. For example, they might recognize that a fine-tuned small model with retrieval augmentation offers the best balance for a given use case – providing accuracy with low latency and cost – whereas another task truly needs a cutting-edge LLM and justifies its expense. The decision flow and criteria we presented help navigate these choices systematically, ensuring factors like domain specificity, data availability, latency requirements, and compliance are all weighed.</p>
<p>Ultimately, building sustainable AI agents is an <strong>iterative journey of adaptation</strong>. Start with straightforward solutions and add complexity only as needed. Use the short/mid/long-term roadmap to gradually layer capabilities, all the while monitoring outcomes. And remain flexible: as new techniques (perhaps better multi-modal models or safer training methods) become available, incorporate them if they fit your framework and improve the goals of capability, cost, or risk.</p>
<p>Banking has long been a data-driven industry, and the promise of agentic AI is immense – from democratizing financial knowledge for customers to augmenting employees with intelligent assistants. Realizing this promise at scale will require not just clever models, but <strong>wise model selection and governance</strong>. By treating model choice as a strategic decision and continuously aligning it with use case needs, organizations can harness AI’s power responsibly. In doing so, they set the stage for AI systems that deliver high impact <em>and</em> high trust – a combination that will define the winners in the next era of digital banking.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="footnotes">Footnotes<a href="#footnotes" class="hash-link" aria-label="Direct link to Footnotes" title="Direct link to Footnotes" translate="no">​</a></h2>
<ol>
<li class="">
<p>Gartner Press Release (July 29, 2024). <em>&quot;30% of Generative AI Projects Will Be Abandoned After Proof of Concept by End of 2025.&quot;</em> Gartner cites poor data quality, inadequate risk controls, rising costs and unclear value as top reasons for failure<a href="https://www.gartner.com/en/newsroom/press-releases/2024-07-29-gartner-predicts-30-percent-of-generative-ai-projects-will-be-abandoned-after-proof-of-concept-by-end-of-2025#:~:text=At%20least%2030,value%2C%20according%20to%20Gartner%2C%20Inc" target="_blank" rel="noopener noreferrer" class="">gartner.com</a>. ↩ ↩2</p>
</li>
<li class="">
<p>Gartner Press Release (Oct 21, 2024). <em>&quot;Four Emerging Challenges to Delivering Value from AI Safely and at Scale.&quot;</em> A survey of CIOs found over 90% concerned with AI costs; Gartner notes <em>“cost is as big an AI risk as security or hallucinations.”</em><a href="https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-four-emerging-challenges-to-delivering-value-from-ai-safely-and-at-scale#:~:text=The%20Cost%20of%20AI%20Can,risk%20as%20security%20or%20hallucinations" target="_blank" rel="noopener noreferrer" class="">gartner.com</a> ↩ ↩2</p>
</li>
<li class="">
<p>F. Wang et al. (2025). <em>A Survey on Collaborating Small and Large Language Models.</em> (arXiv 2510.13890). Highlights that while LLMs have advanced capabilities, they incur high fine-tuning and inference costs and latency, whereas SLMs offer efficiency and edge deployability<a href="https://www.arxiv.org/abs/2510.13890#:~:text=,a%20systematic%20survey%20of%20SLM" target="_blank" rel="noopener noreferrer" class="">arxiv.org</a>. Industry data suggests training frontier LLMs can exceed $100M, and inference cost-per-query can be 100× higher than for smaller models<a href="https://labelyourdata.com/articles/llm-fine-tuning/slm-vs-llm#:~:text=5,million%20queries%20by%20over%20100x" target="_blank" rel="noopener noreferrer" class="">labelyourdata.com</a>. ↩ ↩2 ↩3 ↩4 ↩5</p>
</li>
<li class="">
<p>A. Bora &amp; H. Cuayáhuitl (2024). <em>“Systematic Analysis of RAG-Based LLMs for Medical Chatbots.”</em> (Machine Learning &amp; Knowledge Extraction). Demonstrates that Retrieval-Augmented Generation improves factual accuracy and reduces hallucinations: <em>“RAG effectively reduces the problem of generating factually incorrect content.”</em><a href="https://www.mdpi.com/2504-4990/6/4/116#:~:text=technique%20used%20for%20enhancing%20the,then%20encoded%20into%20a%20vectorised" target="_blank" rel="noopener noreferrer" class="">mdpi.com</a> Also notes combining RAG with fine-tuning yielded best results in domain QA tasks<a href="https://www.mdpi.com/2504-4990/6/4/116#:~:text=,are%20key%20for%20best%20results" target="_blank" rel="noopener noreferrer" class="">mdpi.com</a>. ↩ ↩2 ↩3</p>
</li>
<li class="">
<p>Gartner Press Release (Sept 9, 2024). <em>&quot;40% of GenAI Solutions Will Be Multimodal by 2027.&quot;</em> Predicts a rapid shift towards multi-modal AI (text, image, audio) in the next few years<a href="https://www.gartner.com/en/newsroom/press-releases/2024-09-09-gartner-predicts-40-percent-of-generative-ai-solutions-will-be-multimodal-by-2027#:~:text=9" target="_blank" rel="noopener noreferrer" class="">gartner.com</a>, from a baseline of only 1% in 2023. Highlights that native multimodal training will unlock new AI capabilities across industries. ↩ ↩2</p>
</li>
<li class="">
<p>R. Bommasani, P. Liang <em>et al.</em> (2023). <em>Holistic Evaluation of Language Models (HELM).</em> Presents a multi-metric evaluation framework covering accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency for language models<a href="https://ar5iv.labs.arxiv.org/html/2211.09110#:~:text=potential%20scenarios%20%28i,models%20and%20metrics%20are%20clearly" target="_blank" rel="noopener noreferrer" class="">ar5iv.labs.arxiv.org</a>. Emphasizes looking beyond accuracy to trade-offs across these metrics. ↩</p>
</li>
<li class="">
<p>Y. Zhu &amp; D. Kang (2025). <em>“Human Data is (Probably) More Expensive Than Compute for Training Frontier LLMs.”</em> Analysis indicating that the expense of human-labeled data for fine-tuning now exceeds marginal compute costs by a factor of ~3.1× for cutting-edge models<a href="https://medium.com/@danieldkang/human-data-is-probably-more-expensive-than-compute-for-training-frontier-llms-3c916ef309e4#:~:text=We%20then%20calculate%20the%20sum,art%20AI%20models" target="_blank" rel="noopener noreferrer" class="">medium.com</a>. Case studies showed data labeling costs outpacing training costs (e.g. $60k in annotations vs $360 compute in one example)<a href="https://medium.com/@danieldkang/human-data-is-probably-more-expensive-than-compute-for-training-frontier-llms-3c916ef309e4#:~:text=If%20we%20estimate%20that%20a,marginal%20compute%20cost%20for%20training" target="_blank" rel="noopener noreferrer" class="">medium.com</a>, underscoring the importance of data in model adaptation efforts. ↩ ↩2</p>
</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/whitepaper/tags/banking">banking</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/whitepaper/tags/ai">ai</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/whitepaper/tags/agentic-ai">agentic-ai</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/whitepaper/tags/model">model</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/whitepaper/tags/llm">llm</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/whitepaper/tags/slm">slm</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/whitepaper/tags/nlm">nlm</a></li></ul></div></div><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-11-19T02:26:31.000Z" itemprop="dateModified">Nov 19, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/whitepaper/enabling-agentic-ai-through-well-defined-api-contracts"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Enabling Agentic AI Through Well-Defined API Contracts</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/whitepaper/high-impact-use-cases"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">High-Impact Use Cases and Strategic Insights</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#executive-summary" class="table-of-contents__link toc-highlight">Executive Summary</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#technical-fundamentals" class="table-of-contents__link toc-highlight">Technical Fundamentals</a></li><li><a href="#deep-dive-topics" class="table-of-contents__link toc-highlight">Deep Dive Topics</a><ul><li><a href="#taxonomy-of-model-options-llm-vs-slm-vs-nlm" class="table-of-contents__link toc-highlight">Taxonomy of Model Options: LLM vs SLM vs NLM</a></li><li><a href="#choosing-an-adaptation-strategy-prompting-vs-rag-vs-fine-tuning" class="table-of-contents__link toc-highlight">Choosing an Adaptation Strategy: Prompting vs RAG vs Fine-Tuning</a></li><li><a href="#cost-and-effort-of-fine-tuning" class="table-of-contents__link toc-highlight">Cost and Effort of Fine-Tuning</a></li><li><a href="#multi-modal-models-in-retail-banking" class="table-of-contents__link toc-highlight">Multi-Modal Models in Retail Banking</a></li><li><a href="#cost-optimization-techniques" class="table-of-contents__link toc-highlight">Cost Optimization Techniques</a></li><li><a href="#risk-and-governance-considerations" class="table-of-contents__link toc-highlight">Risk and Governance Considerations</a></li></ul></li><li><a href="#recommendations--roadmap" class="table-of-contents__link toc-highlight">Recommendations &amp; Roadmap</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li><li><a href="#footnotes" class="table-of-contents__link toc-highlight">Footnotes</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/whitepaper/">Home</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>