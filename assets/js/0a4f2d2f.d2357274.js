"use strict";(globalThis.webpackChunkai_whitepaper=globalThis.webpackChunkai_whitepaper||[]).push([[2310],{2315:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>r,default:()=>g,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"selecting-the-right-ai-model","title":"Selecting the Right AI Model","description":"","source":"@site/docs/05-selecting-the-right-ai-model.md","sourceDirName":".","slug":"/selecting-the-right-ai-model","permalink":"/whitepaper/selecting-the-right-ai-model","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"ai","permalink":"/whitepaper/tags/ai"},{"inline":true,"label":"agentic-ai","permalink":"/whitepaper/tags/agentic-ai"},{"inline":true,"label":"banking","permalink":"/whitepaper/tags/banking"}],"version":"current","lastUpdatedAt":1763492571000,"sidebarPosition":5,"frontMatter":{"title":"Selecting the Right AI Model","date":"2025-11-13T10:00:00.000Z","slug":"selecting-the-right-ai-model","authors":["lkgarcia"],"tags":["ai","agentic-ai","banking"],"prompt":"Title: Selecting the Right AI Model: A Framework for Building Reliable and Scalable Agentic Systems\\n\\nMessage: Effective model selection in agentic AI for retail banking requires a disciplined framework that balances capability, adaptability, cost, latency, risk, and governance. This paper provides a decision model for choosing among Large Language Models (LLMs), Small Language Models (SLMs), Narrow / Specialized Models (NLMs), and adaptation strategies (prompt-only, retrieval augmentation, fine-tuning, multi-modal integration) to build reliable, scalable agent systems.\\n\\nPurpose: Deliver an actionable, evidence-based framework to guide architects and product leaders in selecting and adapting language and multi-modal models for high-impact retail banking use cases (e.g., personalized financial guidance, fraud signal triage, customer service orchestration) while controlling cost and risk.\\n\\nGoals:\\n  - Define classification taxonomy: LLM vs SLM vs NLM (capability, cost, latency, governance trade-offs).\\n  - Provide criteria for when to use: (a) LLM + context/prompt engineering only, (b) Retrieval-Augmented Generation (RAG), (c) Fine-tuning, (d) Multi-modal models.\\n  - Quantify cost & effort dimensions of fine-tuning (data acquisition, cleaning, annotation, infra, evaluation, ongoing drift management).\\n  - Outline evaluation dimensions: accuracy, hallucination rate, latency, cost per 1K tokens, privacy/compliance surface, operational maturity.\\n  - Present model selection decision flow (Mermaid diagram) from use case attributes (complexity, domain specificity, data readiness, regulatory sensitivity) to adaptation strategy.\\n  - Provide pragmatic 3-phase roadmap (short, mid, long-term) for model portfolio evolution in retail banking.\\n  - Highlight emerging role of multi-modal (text + document imaging, receipts, statements) and constraints.\\n  - Embed cost optimization levers (model sizing, caching, distillation, tiered routing, selective RAG scopes).\\n\\nAudience: Technical product managers, enterprise/solution architects, AI platform leads, and senior banking executives (mixed technical / non-technical). Assumes familiarity with AI concepts but not deep research expertise.\\n\\nTone: Clear, authoritative, pragmatic; moderately technical yet accessible; caveated where speculative; avoids hype and vendor promotion.\\n\\nLength & structure:\\n  - Target: ~1200\u20131600 words total.\\n  - Use plain Markdown headings (no bold), concise paragraphs, bullets, and one Mermaid diagram (decision flow).\\n  - Inline citations with footnotes: [^n] referencing reputable sources (ArXiv papers, Gartner insights, recognized universities/researchers).\\n  - Minimize jargon; define terms on first use.\\n\\nSections:\\n  1) Executive summary (100\u2013150 words): Core thesis + decision framework value.\\n  2) Introduction: Why disciplined model selection matters now (cost pressure, reliability, governance).\\n  3) Technical fundamentals:\\n     - Model scale vs capability vs latency (parameters, context window, throughput).\\n     - Adaptation continuum: prompt engineering \u2192 RAG \u2192 fine-tuning \u2192 multi-modal integration.\\n     - Evaluation & risk axes (accuracy, hallucination, compliance, cost kinetics, observability).\\n  4) Topics (deep dive):\\n     - Taxonomy: LLM vs SLM vs NLM (definition, strengths, limitations, when to choose each).\\n     - Strategy comparison: LLM + system prompt vs RAG vs Fine-Tuning (decision criteria: domain specificity, update frequency, data volume, risk tolerance).\\n     - Cost & effort model of fine-tuning (stages, typical resource consumption, breakeven thresholds).\\n     - Multi-modal models in retail banking (document ingestion, statement understanding, fraud evidence).\\n     - Cost dimension & optimization (pricing structures, batching, caching, distillation, model routing, guardrail execution costs).\\n     - Risk & governance (hallucination mitigation, leakage prevention, bias monitoring, auditability).\\n  5) Recommendations & roadmap:\\n     - Short-term: Establish evaluation harness, start with SLM or efficient LLM + robust system prompts + guardrails.\\n     - Mid-term: Introduce RAG over curated, governed internal knowledge base; selective fine-tuning for narrow classification tasks.\\n     - Long-term: Portfolio optimization (model routing & distillation), multi-modal expansion, continuous cost governance & drift management.\\n  6) Conclusion: Reinforce disciplined selection + adaptive strategy as foundation for sustainable agentic AI scaling.\\n\\nDecision diagram (Mermaid) guidance: Flow from use case inputs (domain specificity, update velocity, required explainability, available labeled data, latency budget, cost constraints) to recommended path (Prompt-only LLM, SLM, RAG, Fine-tune, Multi-modal extension).\\n\\nExamples & requirements:\\n  - 3-point roadmap (short / mid / long).\\n  - Emphasis on retail banking scenarios; avoid naming specific banks or jurisdictions.\\n  - No regulatory specifics; keep governance general (privacy, auditability).\\n\\nConstraints: Avoid vendor promotion; provide caveats for emerging capabilities; no unrealistic timelines; no unsupported performance claims.\\n\\nSources (target at least 6 distinct footnotes): Mix of ArXiv (model scaling, RAG efficiency), Gartner (enterprise adoption / cost trends), and leading academic institutions (e.g., Stanford, MIT, Oxford) on evaluation, hallucination mitigation, and multi-modal advances.\\n\\nOutput Format: Single downloadable Markdown file ready for Docusaurus docs pipeline.\\n"},"sidebar":"docsSidebar","previous":{"title":"Enabling Agentic AI Through Well-Defined API Contracts","permalink":"/whitepaper/enabling-agentic-ai-through-well-defined-api-contracts"},"next":{"title":"High-Impact Use Cases and Strategic Insights","permalink":"/whitepaper/high-impact-use-cases"}}');var a=n(4848),o=n(8453);const s={title:"Selecting the Right AI Model",date:new Date("2025-11-13T10:00:00.000Z"),slug:"selecting-the-right-ai-model",authors:["lkgarcia"],tags:["ai","agentic-ai","banking"],prompt:"Title: Selecting the Right AI Model: A Framework for Building Reliable and Scalable Agentic Systems\n\nMessage: Effective model selection in agentic AI for retail banking requires a disciplined framework that balances capability, adaptability, cost, latency, risk, and governance. This paper provides a decision model for choosing among Large Language Models (LLMs), Small Language Models (SLMs), Narrow / Specialized Models (NLMs), and adaptation strategies (prompt-only, retrieval augmentation, fine-tuning, multi-modal integration) to build reliable, scalable agent systems.\n\nPurpose: Deliver an actionable, evidence-based framework to guide architects and product leaders in selecting and adapting language and multi-modal models for high-impact retail banking use cases (e.g., personalized financial guidance, fraud signal triage, customer service orchestration) while controlling cost and risk.\n\nGoals:\n  - Define classification taxonomy: LLM vs SLM vs NLM (capability, cost, latency, governance trade-offs).\n  - Provide criteria for when to use: (a) LLM + context/prompt engineering only, (b) Retrieval-Augmented Generation (RAG), (c) Fine-tuning, (d) Multi-modal models.\n  - Quantify cost & effort dimensions of fine-tuning (data acquisition, cleaning, annotation, infra, evaluation, ongoing drift management).\n  - Outline evaluation dimensions: accuracy, hallucination rate, latency, cost per 1K tokens, privacy/compliance surface, operational maturity.\n  - Present model selection decision flow (Mermaid diagram) from use case attributes (complexity, domain specificity, data readiness, regulatory sensitivity) to adaptation strategy.\n  - Provide pragmatic 3-phase roadmap (short, mid, long-term) for model portfolio evolution in retail banking.\n  - Highlight emerging role of multi-modal (text + document imaging, receipts, statements) and constraints.\n  - Embed cost optimization levers (model sizing, caching, distillation, tiered routing, selective RAG scopes).\n\nAudience: Technical product managers, enterprise/solution architects, AI platform leads, and senior banking executives (mixed technical / non-technical). Assumes familiarity with AI concepts but not deep research expertise.\n\nTone: Clear, authoritative, pragmatic; moderately technical yet accessible; caveated where speculative; avoids hype and vendor promotion.\n\nLength & structure:\n  - Target: ~1200\u20131600 words total.\n  - Use plain Markdown headings (no bold), concise paragraphs, bullets, and one Mermaid diagram (decision flow).\n  - Inline citations with footnotes: [^n] referencing reputable sources (ArXiv papers, Gartner insights, recognized universities/researchers).\n  - Minimize jargon; define terms on first use.\n\nSections:\n  1) Executive summary (100\u2013150 words): Core thesis + decision framework value.\n  2) Introduction: Why disciplined model selection matters now (cost pressure, reliability, governance).\n  3) Technical fundamentals:\n     - Model scale vs capability vs latency (parameters, context window, throughput).\n     - Adaptation continuum: prompt engineering \u2192 RAG \u2192 fine-tuning \u2192 multi-modal integration.\n     - Evaluation & risk axes (accuracy, hallucination, compliance, cost kinetics, observability).\n  4) Topics (deep dive):\n     - Taxonomy: LLM vs SLM vs NLM (definition, strengths, limitations, when to choose each).\n     - Strategy comparison: LLM + system prompt vs RAG vs Fine-Tuning (decision criteria: domain specificity, update frequency, data volume, risk tolerance).\n     - Cost & effort model of fine-tuning (stages, typical resource consumption, breakeven thresholds).\n     - Multi-modal models in retail banking (document ingestion, statement understanding, fraud evidence).\n     - Cost dimension & optimization (pricing structures, batching, caching, distillation, model routing, guardrail execution costs).\n     - Risk & governance (hallucination mitigation, leakage prevention, bias monitoring, auditability).\n  5) Recommendations & roadmap:\n     - Short-term: Establish evaluation harness, start with SLM or efficient LLM + robust system prompts + guardrails.\n     - Mid-term: Introduce RAG over curated, governed internal knowledge base; selective fine-tuning for narrow classification tasks.\n     - Long-term: Portfolio optimization (model routing & distillation), multi-modal expansion, continuous cost governance & drift management.\n  6) Conclusion: Reinforce disciplined selection + adaptive strategy as foundation for sustainable agentic AI scaling.\n\nDecision diagram (Mermaid) guidance: Flow from use case inputs (domain specificity, update velocity, required explainability, available labeled data, latency budget, cost constraints) to recommended path (Prompt-only LLM, SLM, RAG, Fine-tune, Multi-modal extension).\n\nExamples & requirements:\n  - 3-point roadmap (short / mid / long).\n  - Emphasis on retail banking scenarios; avoid naming specific banks or jurisdictions.\n  - No regulatory specifics; keep governance general (privacy, auditability).\n\nConstraints: Avoid vendor promotion; provide caveats for emerging capabilities; no unrealistic timelines; no unsupported performance claims.\n\nSources (target at least 6 distinct footnotes): Mix of ArXiv (model scaling, RAG efficiency), Gartner (enterprise adoption / cost trends), and leading academic institutions (e.g., Stanford, MIT, Oxford) on evaluation, hallucination mitigation, and multi-modal advances.\n\nOutput Format: Single downloadable Markdown file ready for Docusaurus docs pipeline.\n"},r="Selecting the Right AI Model: A Framework for Building Reliable and Scalable Agentic Systems",l={},c=[];function d(e){const i={admonition:"admonition",h1:"h1",header:"header",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.admonition,{title:"WORK IN PROGRESS",type:"warning"}),"\n",(0,a.jsx)(i.header,{children:(0,a.jsx)(i.h1,{id:"selecting-the-right-ai-model-a-framework-for-building-reliable-and-scalable-agentic-systems",children:"Selecting the Right AI Model: A Framework for Building Reliable and Scalable Agentic Systems"})})]})}function g(e={}){const{wrapper:i}={...(0,o.R)(),...e.components};return i?(0,a.jsx)(i,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>s,x:()=>r});var t=n(6540);const a={},o=t.createContext(a);function s(e){const i=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(o.Provider,{value:i},e.children)}}}]);