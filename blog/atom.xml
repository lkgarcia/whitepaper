<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lkgarcia.github.io/whitepaper/blog</id>
    <title>White Paper Blog</title>
    <updated>2025-11-13T23:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lkgarcia.github.io/whitepaper/blog"/>
    <subtitle>White Paper Blog</subtitle>
    <icon>https://lkgarcia.github.io/whitepaper/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Agentic AI in Banking]]></title>
        <id>https://lkgarcia.github.io/whitepaper/blog/agentic-ai-in-banking</id>
        <link href="https://lkgarcia.github.io/whitepaper/blog/agentic-ai-in-banking"/>
        <updated>2025-11-13T23:00:00.000Z</updated>
        <summary type="html"><![CDATA[Goal]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="goal">Goal<a href="https://lkgarcia.github.io/whitepaper/blog/agentic-ai-in-banking#goal" class="hash-link" aria-label="Direct link to Goal" title="Direct link to Goal" translate="no">​</a></h2>
<p>The <em>Agentic AI in Banking</em> white paper series aims to <strong>define the strategic and technical foundation</strong> for adopting AI agents within the enterprise. It seeks to <strong>influence the bank’s AI strategy</strong>, <strong>accelerate technical readiness</strong>, and <strong>establish internal standards</strong> for the secure and effective design, deployment, and governance of enterprise-grade agentic systems.</p>
<p>The series progressively builds understanding from foundational concepts to implementation blueprints. Each paper integrates synthesized research, academic frameworks, and practical banking applications to equip executes, architects and engineers with the knowledge, tools, and governance patterns required to realize the full potential of agentic AI under regulated conditions.</p>
<p>Ultimately, the series will culminate in a <strong>Banking AI Agent Reference Architecture and Adoption Framework</strong>, enabling cohesive alignment across strategy, technology, and risk governance while positioning the bank as a frontrunner in responsible, enterprise-grade AI innovation.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="series-overview">Series Overview<a href="https://lkgarcia.github.io/whitepaper/blog/agentic-ai-in-banking#series-overview" class="hash-link" aria-label="Direct link to Series Overview" title="Direct link to Series Overview" translate="no">​</a></h2>
<table><thead><tr><th style="text-align:center">No.</th><th style="text-align:left">Series</th><th style="text-align:left">Focus Area</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:left"><strong>Banking Reimagined Through Agentic AI</strong></td><td style="text-align:left">Foundational concepts</td></tr><tr><td style="text-align:center">2</td><td style="text-align:left"><strong>Balancing Autonomy and Agency: Managing Emerging Risks in AI Agents</strong></td><td style="text-align:left">Risk management</td></tr><tr><td style="text-align:center">3</td><td style="text-align:left"><strong>The AI Use Case Canvas: A Structured Framework for Evaluating and Prioritizing AI Initiatives</strong></td><td style="text-align:left">Strategic enablement</td></tr><tr><td style="text-align:center">4</td><td style="text-align:left"><strong>Enabling Agentic AI Through Well-Defined API Contracts: Building Reliable and Scalable Toolchains</strong></td><td style="text-align:left">Technical enablement</td></tr><tr><td style="text-align:center">5</td><td style="text-align:left"><strong>Selecting the Right AI Model: A Framework for Building Reliable and Scalable Agentic Systems</strong></td><td style="text-align:left">Technical enablement</td></tr><tr><td style="text-align:center">6</td><td style="text-align:left"><strong>Agentic AI in Banking: High-Impact Use Cases and Strategic Insights for Measurable Business Value</strong></td><td style="text-align:left">Real-World Business applications</td></tr><tr><td style="text-align:center">7</td><td style="text-align:left"><strong>Building Enterprise AI Agents: Empowering Business Units Through Secure, Scalable, and Compliant AI Platforms</strong></td><td style="text-align:left">Enterprise adoption</td></tr></tbody></table>]]></content>
        <author>
            <name>Kevin Garcia</name>
            <uri>https://github.com/lkgarcia</uri>
        </author>
        <category label="ai" term="ai"/>
        <category label="agentic-ai" term="agentic-ai"/>
        <category label="banking" term="banking"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Banking Reimagined Through Agentic AI]]></title>
        <id>https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai</id>
        <link href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai"/>
        <updated>2025-11-13T22:00:00.000Z</updated>
        <summary type="html"><![CDATA[image-center]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="image-center" src="https://lkgarcia.github.io/whitepaper/assets/images/hero-7e52033f82245798595dd99112640219.png" width="1024" height="608" class="img_ev3q"></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="executive-summary">Executive Summary<a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#executive-summary" class="hash-link" aria-label="Direct link to Executive Summary" title="Direct link to Executive Summary" translate="no">​</a></h2>
<p>Agentic AI – AI systems endowed with autonomous decision-making – promises to transform retail banking by enabling AI “agents” to act on behalf of customers and employees. Unlike traditional analytics or chatbots, agentic AI can <strong>plan, decide, and execute</strong> tasks with minimal human intervention, potentially handling everything from routine customer service requests to complex fraud investigations. This white paper explains the fundamentals of agentic AI and how it builds on prior AI paradigms, illustrates a visionary customer service scenario with AI agents interacting, and surveys emerging industry trends. The goal is to inform banking leaders about this new AI frontier and provide actionable guidance on leveraging autonomous agents to reimagine banking services.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>The banking sector is experiencing rapid innovation in artificial intelligence. Recent advances in <strong>generative AI</strong> (e.g. large language models capable of producing human-like text) have already begun to augment customer service, fraud detection, and more.</p>
<p><img decoding="async" loading="lazy" src="https://placehold.co/600x400?text=Evolution+of+AI" alt="image-center" class="img_ev3q"></p>
<blockquote>
<p><em>"By 2028, organizations that leverage multiagent AI for 80% of customer-facing business processes will dominate."</em></p>
<p><em>- Gartner, 2025<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-1-35b454" id="user-content-fnref-1-35b454" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">1</a></sup></em></p>
</blockquote>
<p>Now, a new evolution is underway toward <strong>“agentic AI,”</strong> where AI systems don’t just inform humans but can <strong>take action</strong> on their own. In banking, this means moving beyond static chatbots or decision support tools to AI-driven agents that can autonomously perform tasks – from executing transactions to answering complex customer requests – all while navigating the bank’s systems and rules. This paradigm shift carries significant implications for retail banking: it offers the potential for unprecedented efficiency and 24/7 personalized service, but also demands careful design to ensure compliance, security, and trust. In this paper, we explore what agentic AI is, how it can be applied in banking, a forward-looking scenario of agents in action, current industry developments, and recommendations for banks to adopt these technologies strategically.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="technical-fundamentals-of-agentic-ai">Technical Fundamentals of Agentic AI<a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#technical-fundamentals-of-agentic-ai" class="hash-link" aria-label="Direct link to Technical Fundamentals of Agentic AI" title="Direct link to Technical Fundamentals of Agentic AI" translate="no">​</a></h2>
<p><strong>What is an AI agent?</strong> In simple terms, an AI “agent” is a software entity empowered with <em>agency</em> – the ability to make independent decisions and initiate actions toward a goal<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-2-35b454" id="user-content-fnref-2-35b454" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">2</a></sup>. Traditional AI systems (including many ML models and chatbots) typically provide insights or outputs <em>when prompted by a user</em>, but an agent goes further: it can proactively plan steps and act on a user’s or organization’s behalf.</p>
<p><strong>Anatomy of an AI agent:</strong> Most agentic AI systems share a common architecture. They are often built on a foundation of large language models or similar AI engines that can reason and generate plans. On top of this “brain,” agents have several key components:</p>
<ul>
<li class=""><strong>Goal or Intent:</strong> A defined objective or problem to solve (provided by a user or another system).</li>
<li class=""><strong>Planning Module:</strong> The ability to break down goals into actionable steps and make decisions in sequence. This often involves iterative reasoning (sometimes using techniques like chain-of-thought prompting or planners) to determine <em>what</em> actions to take.</li>
<li class=""><strong>Tools and Actuators:</strong> Interfaces to the external environment that let the agent execute actions. These could be APIs, RPA (robotic process automation) scripts, databases, web services, or other software that the agent can call. For instance, an agent may call a core banking API to transfer funds or use a document parser to read a form.</li>
<li class=""><strong>Memory/Context:</strong> Mechanisms to store and recall information from past interactions. This ensures continuity and allows the agent to handle multi-step workflows (keeping track of prior outputs, user preferences, interim results, etc.). Some agents maintain an internal knowledge base or can retrieve external knowledge (via search or retrieval-augmented generation).</li>
<li class=""><strong>Sensors/Perception:</strong> In software terms, this means the agent’s ability to receive data from its environment – such as user input, transaction data, or alerts. It “perceives” the state of relevant systems before deciding actions.</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://placehold.co/600x400?text=Anatomy+of+an+AI+agent" alt="image-center" class="img_ev3q"></p>
<p>Together, these components enable a cycle of <em>perceive → decide → act</em>. The agent perceives inputs or changes, reasons about what to do, then takes actions, possibly generating new inputs in a loop. Crucially, agentic AI systems are designed to operate with <strong>minimal human supervision</strong> once deployed, within the bounds of their defined goals and permissions<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-2-35b454" id="user-content-fnref-2-35b454-2" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">2</a></sup>. This sets them apart from earlier AI assistants or analytic models that required a human to initiate every action.</p>
<p><strong>From Assistants to Autonomous Agents:</strong> Agentic AI marks the next step in banking’s AI evolution. Early systems relied on rules and scripts, followed by reactive ML models and chatbots. Now, agentic AI combines advanced models with automation to enable proactive, goal-driven behavior<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-2-35b454" id="user-content-fnref-2-35b454-3" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">2</a></sup>. Instead of assisting humans step by step, agents can manage entire processes—like loan approvals—independently. Humans shift from task execution to setting goals and guardrails.</p>
<p>While advancing quickly, fully autonomous banking agents remain in early stages. Most current uses are narrow—like basic bots or single-step tasks—due to the difficulty of reliably managing complex workflows<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-3-35b454" id="user-content-fnref-3-35b454" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">3</a></sup>. Research shows that even top-tier models struggle with domain knowledge and multi-step reasoning, lagging far behind human experts<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-4-35b454" id="user-content-fnref-4-35b454" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">4</a></sup>. Realizing the full vision requires further progress in reasoning, reliability, and system integration.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="future-in-action-agent-to-agent-customer-service-interaction">Future in Action: Agent-to-Agent Customer Service Interaction<a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#future-in-action-agent-to-agent-customer-service-interaction" class="hash-link" aria-label="Direct link to Future in Action: Agent-to-Agent Customer Service Interaction" title="Direct link to Future in Action: Agent-to-Agent Customer Service Interaction" translate="no">​</a></h2>
<p><img decoding="async" loading="lazy" alt="Agentic AI Concept" src="https://lkgarcia.github.io/whitepaper/assets/images/agentic-ai-concept-86bc54cc6cafb43752f661c31721e708.svg" width="1207" height="847" class="img_ev3q"></p>
<p>This scenario illustrates how AI agents in retail banking can autonomously collaborate to fulfill a high-value customer request—such as transferring $50,000 internationally—while embedding compliance and oversight.</p>
<ol>
<li class=""><strong>Customer Agent Initiates:</strong> The customer’s AI assistant sends a transfer request to the bank’s service agent.</li>
<li class=""><strong>Service Agent Plans:</strong> It authenticates the request and detects the need for a compliance check.</li>
<li class=""><strong>Compliance Agent Reviews:</strong> This agent screens the transaction for AML/KYC issues and flags concerns if needed.</li>
<li class=""><strong>Decision Point:</strong> If approved, the process proceeds. If flagged, it escalates to a human or requests more data.</li>
<li class=""><strong>Transfer Execution:</strong> The service agent completes the transfer via core banking APIs.</li>
<li class=""><strong>Confirmation:</strong> The service agent notifies the customer’s AI, which relays the result to the user.</li>
</ol>
<p><strong>Benefits:</strong></p>
<ul>
<li class=""><strong>Seamless and Fast:</strong> Full automation delivers near-instant execution, reducing reliance on manual steps.</li>
<li class=""><strong>Personalized Experience:</strong> The customer’s AI communicates in their preferred format, streamlining interaction.</li>
<li class=""><strong>Operational Efficiency:</strong> Multi-step workflows are handled autonomously, freeing human staff for complex tasks.</li>
<li class=""><strong>Regulatory Consistency:</strong> Compliance is embedded, auditable, and enforced uniformly, with human-in-the-loop controls for exceptions.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="industry-trends-in-agentic-ai-adoption">Industry Trends in Agentic AI Adoption<a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#industry-trends-in-agentic-ai-adoption" class="hash-link" aria-label="Direct link to Industry Trends in Agentic AI Adoption" title="Direct link to Industry Trends in Agentic AI Adoption" translate="no">​</a></h2>
<p>As of 2025, agentic AI adoption in banking is <strong>early but accelerating</strong>. Forward-leaning institutions are piloting agents across:</p>
<ul>
<li class=""><strong>Internal Tasks:</strong> Banks are testing agents for report generation, legal document analysis, and transaction monitoring—often targeting well-defined, rule-based use cases<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-2-35b454" id="user-content-fnref-2-35b454-4" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">2</a></sup>.</li>
<li class=""><strong>Customer Service:</strong> Chatbots are evolving into autonomous assistants that can resolve issues end-to-end. Gartner forecasts that by 2029, 80% of routine service tasks may be handled by agents, including those initiated by <strong>machine customers</strong> (AI acting on behalf of users)<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-5-35b454" id="user-content-fnref-5-35b454" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">5</a></sup>.</li>
<li class=""><strong>Automation Integration:</strong> Agents are increasingly embedded in RPA and API workflows. Cloud platforms now offer tools for multi-agent orchestration, accelerating development<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-2-35b454" id="user-content-fnref-2-35b454-5" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">2</a></sup>.</li>
</ul>
<p>Despite growing interest, most deployments remain <strong>cautious and experimental</strong>. “Agent washing” is common—many solutions lack true autonomy<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-4-35b454" id="user-content-fnref-4-35b454-2" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">4</a></sup>. Gartner found only ~130 vendors with credible agentic capabilities, and over 40% of agentic initiatives may be canceled by 2027 due to low ROI<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-7-35b454" id="user-content-fnref-7-35b454" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">6</a></sup>.</p>
<p>Still, the trajectory is clear. By 2028, AI agents could drive 15% of work decisions, and 30% of enterprise software may include agentic components<sup><a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fn-4-35b454" id="user-content-fnref-4-35b454-3" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">4</a></sup>. Banks are preparing by hiring for roles like “AI agent trainer” and building internal capability.</p>
<p>In short, while momentum is building, adoption is tempered by technical, integration, and risk-related hurdles—challenges we explore in the next paper in this series.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>Agentic AI marks a major step forward in banking, offering the potential to transform operations and customer service through intelligent autonomy. Tasks once handled manually can now be performed swiftly by AI agents, enabling faster, more personalized service.</p>
<p>But realizing this vision requires more than technology—it demands strong governance, regulatory alignment, and strategic planning. Banks must innovate carefully, embedding controls that ensure accountability and trust.</p>
<p>Leaders who act now—via targeted pilots and clear safeguards—will be well-positioned to harness agentic AI as a competitive advantage. Ultimately, this evolution isn’t about replacing humans, but elevating them, as AI takes on the routine and enables people to focus on higher-value work.</p>
<hr>
<!-- -->
<section data-footnotes="true" class="footnotes"><h2 class="anchor anchorTargetStickyNavbar_Vzrq sr-only" id="footnote-label">Footnotes<a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#footnote-label" class="hash-link" aria-label="Direct link to Footnotes" title="Direct link to Footnotes" translate="no">​</a></h2>
<ol>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-1-35b454">
<p><a href="https://www.gartner.com/en/newsroom/press-releases/2025-10-21-gartner-unveils-top-predictions-for-it-organizations-and-users-in-2026-and-beyond" target="_blank" rel="noopener noreferrer" class="">Gartner Press Release (2025). <em>Top Predictions for IT Organizations and Users in 2026 and Beyond.</em></a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-1-35b454" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-2-35b454">
<p><a href="https://www.deloitte.com/us/en/insights/industry/financial-services/agentic-ai-banking.html" target="_blank" rel="noopener noreferrer" class="">Deloitte Insights (2025). <em>How banks can supercharge intelligent automation with agentic AI</em>.</a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-2-35b454" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">↩</a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-2-35b454-2" data-footnote-backref="" aria-label="Back to reference 2-2" class="data-footnote-backref">↩<sup>2</sup></a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-2-35b454-3" data-footnote-backref="" aria-label="Back to reference 2-3" class="data-footnote-backref">↩<sup>3</sup></a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-2-35b454-4" data-footnote-backref="" aria-label="Back to reference 2-4" class="data-footnote-backref">↩<sup>4</sup></a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-2-35b454-5" data-footnote-backref="" aria-label="Back to reference 2-5" class="data-footnote-backref">↩<sup>5</sup></a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-3-35b454">
<p><a href="https://www.posh.ai/blog/generative-ai-vs-agentic-ai-in-banking-what-sets-them-apart" target="_blank" rel="noopener noreferrer" class="">Posh AI Blog (2025). <em>Generative AI vs Agentic AI in Banking: What Sets Them Apart</em>.</a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-3-35b454" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref">↩</a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-4-35b454">
<p><a href="https://www.reuters.com/business/over-40-agentic-ai-projects-will-be-scrapped-by-2027-gartner-says-2025-06-25/" target="_blank" rel="noopener noreferrer" class="">Reuters (2025). <em>Over 40% of agentic AI projects will be scrapped by 2027</em>.</a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-4-35b454" data-footnote-backref="" aria-label="Back to reference 4" class="data-footnote-backref">↩</a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-4-35b454-2" data-footnote-backref="" aria-label="Back to reference 4-2" class="data-footnote-backref">↩<sup>2</sup></a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-4-35b454-3" data-footnote-backref="" aria-label="Back to reference 4-3" class="data-footnote-backref">↩<sup>3</sup></a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-5-35b454">
<p><a href="https://www.cmswire.com/the-wire/gartner-predicts-agentic-ai-will-autonomously-resolve-80-of-common-customer-service-issues-without-human-intervention-by-2029/" target="_blank" rel="noopener noreferrer" class="">Gartner Press Release (2025) – via CMSWire. <em>Agentic AI Set to Transform Customer Service &amp; Support</em>.</a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-5-35b454" data-footnote-backref="" aria-label="Back to reference 5" class="data-footnote-backref">↩</a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-7-35b454">
<p><a href="https://www.gartner.com/en/newsroom/press-releases/2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027" target="_blank" rel="noopener noreferrer" class="">Gartner (2025). <em>Press Release: Gartner Predicts Over 40% of Agentic AI Projects Will Be Canceled by 2027</em> (June 25, 2025).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/banking-reimagined-through-agentic-ai#user-content-fnref-7-35b454" data-footnote-backref="" aria-label="Back to reference 6" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section>]]></content>
        <author>
            <name>Kevin Garcia</name>
            <uri>https://github.com/lkgarcia</uri>
        </author>
        <category label="ai" term="ai"/>
        <category label="agentic-ai" term="agentic-ai"/>
        <category label="banking" term="banking"/>
        <category label="future" term="future"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Balancing Autonomy and Agency: Managing Emerging Risks in AI Agents]]></title>
        <id>https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency</id>
        <link href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency"/>
        <updated>2025-11-13T21:00:00.000Z</updated>
        <summary type="html"><![CDATA[image-center]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" src="https://placehold.co/800x400?text=Hero+Image" alt="image-center" class="img_ev3q"></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="executive-summary">Executive Summary<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#executive-summary" class="hash-link" aria-label="Direct link to Executive Summary" title="Direct link to Executive Summary" translate="no">​</a></h2>
<p>Autonomous AI agents offer major efficiency gains but introduce new risk dimensions. This paper defines two critical factors—<strong>agency</strong> (decision-making power) and <strong>autonomy</strong> (independence from human oversight)—and explains why balancing them is essential. We map common failure modes to agent architectures and provide a practical roadmap for banks to pilot, scale, and govern agentic AI safely. Key controls include auditability, human-in-the-loop checkpoints, and constrained tool access. A step-by-step scenario illustrates how agents can coordinate safely in high-stakes workflows like payment disputes. With thoughtful design and proactive governance, banks can unlock agentic AI’s value while managing its risks.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>In the previous paper in this series, <em>Banking Reimagined Through Agentic AI</em>, we explored the next evolution of artificial intelligence—Agentic AI—and its potential to transform banking operations and customer service by enabling AI agents to act on behalf of customers and employees.</p>
<p>By 2025, nearly half of banks had created “AI supervisor” roles, reflecting rapid adoption of agentic AI. Common use cases include customer-facing chatbots (75% of banks), fraud detection agents (two-thirds), and internal digital assistants for loans or IT<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-a-6be171" id="user-content-fnref-a-6be171" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">1</a></sup>. While the potential value is estimated at <strong>$450 billion</strong>, these agents introduce <strong>unique risks</strong>—unlike traditional software, they make complex decisions, adapt behaviors, and interact across systems in often <strong>unpredictable</strong> ways.</p>
<p>Regulators and executives are taking notice. In 2024, the U.S. Consumer Financial Protection Bureau warned that poorly governed banking chatbots risk compliance violations by mishandling disputes or giving incorrect information<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-b-6be171" id="user-content-fnref-b-6be171" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">2</a></sup>. Globally, oversight expectations are rising. Similarly, the EU’s upcoming AI Act classifies many financial AI systems as “high risk,” requiring strict controls on privacy, fairness, and human accountability.</p>
<blockquote>
<p><em>Singapore’s central bank (MAS) proposed holding boards directly accountable for AI failures, warning that <strong>“AI agents with greater autonomy and tool access could amplify risks”</strong> if not properly governed.</em></p>
<p><em>- CIO.com (2025)<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-c-6be171" id="user-content-fnref-c-6be171" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">3</a></sup></em></p>
</blockquote>
<p>This white paper focuses on <strong>banking</strong> use cases and the emerging risks of AI agents. We explore how <strong>agency</strong> and <strong>autonomy</strong> enable powerful capabilities but also introduce new failure modes<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-d-6be171" id="user-content-fnref-d-6be171" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">4</a></sup>. We offer practical guidance—from design choices (e.g. limiting autonomy) to governance practices (e.g. auditability, human oversight)—and present a three-phase roadmap (pilot → scale → govern) to help banks deploy agentic AI responsibly, driving innovation <strong>without</strong> compromising compliance, security, or trust.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="core-concepts-agency-and-autonomy-in-ai-agents">Core Concepts: Agency and Autonomy in AI Agents<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#core-concepts-agency-and-autonomy-in-ai-agents" class="hash-link" aria-label="Direct link to Core Concepts: Agency and Autonomy in AI Agents" title="Direct link to Core Concepts: Agency and Autonomy in AI Agents" translate="no">​</a></h2>
<p>To assess risk, it's critical to define <strong>agency</strong> and <strong>autonomy</strong> in AI systems and understand their roles in agent behavior.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-is-agency">What is Agency?<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#what-is-agency" class="hash-link" aria-label="Direct link to What is Agency?" title="Direct link to What is Agency?" translate="no">​</a></h3>
<p><em>Agency</em> refers to an AI’s capacity to act purposefully, make decisions, and influence its environment on behalf of users. Unlike rule-based bots, agentic systems can interpret goals, take initiative, and adapt strategies—even in novel situations<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-e-6be171" id="user-content-fnref-e-6be171" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">5</a></sup>. For example, a high-agency service agent might analyze financial data and initiate loan processing, while a low-agency one simply retrieves information. Greater agency enables flexibility but increases risk if misaligned with intent or policy.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-is-autonomy">What is Autonomy?<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#what-is-autonomy" class="hash-link" aria-label="Direct link to What is Autonomy?" title="Direct link to What is Autonomy?" translate="no">​</a></h3>
<p><em>Autonomy</em> measures how independently an agent operates without human input. It reflects the level of oversight built into its workflow—from fully supervised to end-to-end execution. Most bank use cases today adopt low to moderate autonomy to preserve control in high-risk scenarios. For instance, a chatbot may handle basic queries autonomously but escalate fraud concerns to a human.</p>
<p>Agency and autonomy are distinct <strong>governance levers</strong>. An agent may have low agency (e.g., limited tools) but high autonomy (e.g., runs unsupervised), or vice versa. Seeking approval signals limited autonomy; modifying systems reflects greater agency. Disentangling the two helps tailor oversight to the nature and risk of the task.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="levels-of-autonomy-in-ai-agents">Levels of Autonomy in AI Agents<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#levels-of-autonomy-in-ai-agents" class="hash-link" aria-label="Direct link to Levels of Autonomy in AI Agents" title="Direct link to Levels of Autonomy in AI Agents" translate="no">​</a></h2>
<p>Autonomy in AI agents exists on a spectrum, not as an all-or-nothing property. A five-level framework—ranging from <strong>Operator</strong> to <strong>Observer</strong>—is commonly used to describe how much independence an agent has in decision-making and execution<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-d-6be171" id="user-content-fnref-d-6be171-2" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">4</a></sup>. This structure clarifies the balance of control between human and AI across different use cases:</p>
<table><thead><tr><th style="text-align:left"><strong>Level</strong></th><th style="text-align:left"><strong>Role</strong></th><th style="text-align:left"><strong>Description</strong></th><th style="text-align:left"><strong>Example</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>1</strong></td><td style="text-align:left">Operator</td><td style="text-align:left">AI acts only when explicitly instructed by a human.</td><td style="text-align:left">A task bot triggered manually to retrieve reports.</td></tr><tr><td style="text-align:left"><strong>2</strong></td><td style="text-align:left">Collaborator</td><td style="text-align:left">AI assists users but requires frequent guidance or intervention.</td><td style="text-align:left">A chatbot that drafts replies but needs staff approval to send them.</td></tr><tr><td style="text-align:left"><strong>3</strong></td><td style="text-align:left">Consultant</td><td style="text-align:left">AI performs defined tasks with some independence, deferring major decisions to humans.</td><td style="text-align:left">A credit risk agent that recommends approvals reviewed by an underwriter.</td></tr><tr><td style="text-align:left"><strong>4</strong></td><td style="text-align:left">Approver</td><td style="text-align:left">AI operates independently in routine tasks, escalating exceptions to humans.</td><td style="text-align:left">A fraud system that blocks common cases but flags unusual ones.</td></tr><tr><td style="text-align:left"><strong>5</strong></td><td style="text-align:left">Observer</td><td style="text-align:left">AI functions autonomously end-to-end, with little to no human involvement.</td><td style="text-align:left">An IT monitoring agent that restarts servers without human input.</td></tr></tbody></table>
<p>In real-world deployments, an agent's autonomy may vary by task or context. For instance, a customer service agent might autonomously answer basic queries but escalate sensitive topics to a human. Many agent designs incorporate such dynamic shifts in autonomy to match risk levels and regulatory expectations.</p>
<p>This tiered approach also aligns with emerging concepts like <strong>AI autonomy certification</strong>, which may eventually help institutions communicate an agent's oversight level more transparently<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-d-6be171" id="user-content-fnref-d-6be171-3" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">4</a></sup>. While formal standards are still evolving, defining and documenting each agent’s autonomy level can support clearer governance, risk assessment, and stakeholder alignment.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="differentiating-risk-agency-vs-autonomy">Differentiating Risk: Agency vs. Autonomy<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#differentiating-risk-agency-vs-autonomy" class="hash-link" aria-label="Direct link to Differentiating Risk: Agency vs. Autonomy" title="Direct link to Differentiating Risk: Agency vs. Autonomy" translate="no">​</a></h2>
<p><strong>Agency</strong> and <strong>autonomy</strong> introduce distinct risk types in AI systems.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="high-agency">High Agency<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#high-agency" class="hash-link" aria-label="Direct link to High Agency" title="Direct link to High Agency" translate="no">​</a></h3>
<p>When an agent has <em>too much capability or access</em>, risks are primarily <strong>impact-based</strong> — i.e., what damage it could cause <em>if it acts incorrectly</em>. Agentic systems may make policy-like decisions that introduce bias, misalign with goals, or reduce explainability, complicating audits and customer resolution.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Example Scenarios</div><div class="admonitionContent_BuS1"><ul>
<li class="">Agent can execute API calls across financial systems.</li>
<li class="">Agent modifies data, triggers transactions, or reconfigures settings.</li>
<li class="">Agent sends external communications (emails, posts, messages).</li>
</ul></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="risk-categories">Risk Categories<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#risk-categories" class="hash-link" aria-label="Direct link to Risk Categories" title="Direct link to Risk Categories" translate="no">​</a></h4>
<table><thead><tr><th><strong>Risk Type</strong></th><th><strong>Description</strong></th><th><strong>Example</strong></th></tr></thead><tbody><tr><td><strong>Operational Risk</strong></td><td>Excessive or incorrect actions cause service disruption or financial loss.</td><td>Agent approves invalid transactions.</td></tr><tr><td><strong>Security Risk</strong></td><td>Unauthorized tool use or privileged access abuse.</td><td>Agent calls admin APIs beyond scope.</td></tr><tr><td><strong>Reputational Risk</strong></td><td>Public-facing actions without validation.</td><td>Agent posts unverified or inappropriate content.</td></tr><tr><td><strong>Compliance Risk</strong></td><td>Violates policy or legal requirements.</td><td>Agent mishandles personal data.</td></tr><tr><td><strong>Cascade Risk</strong></td><td>Tool chaining triggers unintended downstream effects.</td><td>Agent runs a script that impacts multiple systems.</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Analogy</div><div class="admonitionContent_BuS1"><p>Like giving an intern unrestricted access — well-intentioned, but risky at scale.</p></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="high-autonomy">High Autonomy<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#high-autonomy" class="hash-link" aria-label="Direct link to High Autonomy" title="Direct link to High Autonomy" translate="no">​</a></h3>
<p>When an agent operates <em>too independently</em> (without oversight or feedback), risks are primarily <strong>process-based</strong> — i.e., when, how, and under what conditions it acts. Unchecked behavior can result in <strong>disruptions</strong>, <strong>security breaches</strong>, or customer harm — such as chatbots giving false information or exposing sensitive data.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Example Scenarios</div><div class="admonitionContent_BuS1"><ul>
<li class="">Agent runs continuously without checkpoints.</li>
<li class="">Agent self-initiates actions or escalations.</li>
<li class="">Agent adapts policies without validation.</li>
</ul></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="risk-categories-1">Risk Categories<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#risk-categories-1" class="hash-link" aria-label="Direct link to Risk Categories" title="Direct link to Risk Categories" translate="no">​</a></h4>
<table><thead><tr><th><strong>Risk Type</strong></th><th><strong>Description</strong></th><th><strong>Example</strong></th></tr></thead><tbody><tr><td><strong>Control Risk</strong></td><td>Lack of human oversight or auditability.</td><td>Agent acts with no approval history.</td></tr><tr><td><strong>Drift Risk</strong></td><td>Behavioral deviation over time.</td><td>Agent “learns” undesirable patterns or bias.</td></tr><tr><td><strong>Ethical Risk</strong></td><td>Misaligned decisions or fairness violations.</td><td>Agent denies service using biased logic.</td></tr><tr><td><strong>Accountability Risk</strong></td><td>Unclear responsibility for outcomes.</td><td>Who is liable if the agent fails silently?</td></tr><tr><td><strong>Runaway Risk</strong></td><td>Recurring loops or actions without termination.</td><td>Agent retries endlessly or spams actions.</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Analogy</div><div class="admonitionContent_BuS1"><p>Like a self-driving car told to “keep going” — even when conditions change.</p></div></div>
<p>Agency and autonomy often interact, but their risks are distinct: <strong>excess autonomy</strong> drives operational failures, while <strong>excess agency</strong> introduces compliance and strategic exposure. Even low-agency systems can cause harm if left unsupervised, while high-agency systems must be closely governed. Effective AI design requires balancing both based on task sensitivity and organizational risk appetite.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="banking-regulation-and-ai-governance-landscape">Banking Regulation and AI Governance Landscape<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#banking-regulation-and-ai-governance-landscape" class="hash-link" aria-label="Direct link to Banking Regulation and AI Governance Landscape" title="Direct link to Banking Regulation and AI Governance Landscape" translate="no">​</a></h2>
<p>While no unified regulation governs AI agents, global regulators are increasingly setting expectations that address both <strong>agency</strong> and <strong>autonomy</strong> in AI systems.</p>
<p><strong>Human accountability</strong> is a central theme. In 2025, Singapore’s MAS proposed that boards attest to their understanding of deployed AI, warning that greater autonomy could amplify risks like service failures or missed financial crimes<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-c-6be171" id="user-content-fnref-c-6be171-2" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">3</a></sup>. The EU’s draft AI Act classifies credit scoring and fraud detection as “high risk,” requiring human-in-the-loop controls, transparency, and bias testing. In the U.S., existing rules—such as fair lending laws and model risk guidance (SR 11-7)—are being applied to AI, requiring validation, documentation, and monitoring.</p>
<p><strong>Operational risk and consumer protection</strong> are also key. The U.S. CFPB cautioned in 2023 that chatbots must not obstruct customer access to resolution pathways<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-b-6be171" id="user-content-fnref-b-6be171-2" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">2</a></sup>. In the UK, the FCA and Bank of England noted that while most firms use AI, many lack a full understanding of their systems, raising concerns about fairness, security, and explainability<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-g-6be171" id="user-content-fnref-g-6be171" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">6</a></sup>.</p>
<p><strong>Documentation and auditability</strong> are emerging priorities. Regulators expect AI agents’ actions and decisions to be logged—particularly in multi-agent workflows. Some banks have begun developing internal <strong>AI registers</strong> to track models, usage, data inputs, and responsible owners. These may soon become mandatory under laws like the EU AI Act.</p>
<p>Lastly, regulators are signaling that <strong>third-party AI services</strong> fall under the same accountability standards. Banks must apply governance controls not only to internal agents but also to external vendors—extending familiar cloud oversight practices to AI. The core message: <em>banks remain fully responsible for the outcomes of their AI systems</em>, regardless of who builds them.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="real-world-examples-of-ai-governance-failures">Real-World Examples of AI Governance Failures<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#real-world-examples-of-ai-governance-failures" class="hash-link" aria-label="Direct link to Real-World Examples of AI Governance Failures" title="Direct link to Real-World Examples of AI Governance Failures" translate="no">​</a></h2>
<p>Though fully autonomous agents in banking are still emerging, early incidents already highlight governance gaps:</p>
<ul>
<li class="">
<p><strong>Credit Bias and Litigation:</strong> Some banks faced lawsuits after AI credit models disproportionately denied or overcharged minority applicants<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-f-6be171" id="user-content-fnref-f-6be171" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">7</a></sup>. The issue often stemmed from biased training data and unchecked optimization goals—high agency without ethical constraints.</p>
</li>
<li class="">
<p><strong>Chatbot Escalation Failures:</strong> In 2023, regulators received complaints about chatbots mishandling disputes and failing to escalate to humans<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-b-6be171" id="user-content-fnref-b-6be171-3" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">2</a></sup>. One bot confirmed a dispute and promised a refund—but never triggered any backend process, violating resolution timelines.</p>
</li>
<li class="">
<p><strong>Automation Glitches:</strong> In 2024, a bank’s automated system mistakenly showed $0 balances to 20,000 customers, causing panic<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-h-6be171" id="user-content-fnref-h-6be171" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">8</a></sup>. While not AI-driven, the incident illustrates how unmonitored automation can scale errors instantly.</p>
</li>
<li class="">
<p><strong>Data Leakage Risks:</strong> Employees using external AI tools exposed confidential client data<sup><a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fn-i-6be171" id="user-content-fnref-i-6be171" data-footnote-ref="true" aria-describedby="footnote-label" class="anchorTargetStickyNavbar_Vzrq">9</a></sup>, prompting many banks to restrict public chatbot use until secure alternatives were deployed.</p>
</li>
</ul>
<p>These failures weren’t caused by rogue AI—they stemmed from <strong>routine breakdowns in oversight, escalation, and testing</strong>. Each scenario underscores the need for guardrails, auditability, and clear accountability—issues addressed in the next section.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="recommendations-and-roadmap-for-safe-agent-adoption">Recommendations and Roadmap for Safe Agent Adoption<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#recommendations-and-roadmap-for-safe-agent-adoption" class="hash-link" aria-label="Direct link to Recommendations and Roadmap for Safe Agent Adoption" title="Direct link to Recommendations and Roadmap for Safe Agent Adoption" translate="no">​</a></h2>
<p>Effective AI agent deployment in banking requires coordinated <strong>technical controls</strong>, <strong>governance</strong>, and <strong>operational safeguards</strong>. This section outlines key design practices for balancing agency and autonomy, along with a phased rollout strategy.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="balancing-the-two-levers-design-principles">Balancing the Two Levers: Design Principles<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#balancing-the-two-levers-design-principles" class="hash-link" aria-label="Direct link to Balancing the Two Levers: Design Principles" title="Direct link to Balancing the Two Levers: Design Principles" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-limit-agency-for-high-stakes-tasks">1. Limit agency for high-stakes tasks<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#1-limit-agency-for-high-stakes-tasks" class="hash-link" aria-label="Direct link to 1. Limit agency for high-stakes tasks" title="Direct link to 1. Limit agency for high-stakes tasks" translate="no">​</a></h4>
<p>Constrain agents handling sensitive decisions (e.g. credit or fund transfers) by hard-coding rules or using a “policy wrapper” to enforce strict decision boundaries.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Example</div><div class="admonitionContent_BuS1"><p>A loan approval agent can only select from pre-approved loan products and must apply fixed eligibility rules—no dynamic criteria changes or offer generation.</p></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-calibrate-autonomy-to-maturity-and-risk">2. Calibrate autonomy to maturity and risk<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#2-calibrate-autonomy-to-maturity-and-risk" class="hash-link" aria-label="Direct link to 2. Calibrate autonomy to maturity and risk" title="Direct link to 2. Calibrate autonomy to maturity and risk" translate="no">​</a></h4>
<p>Start with low autonomy during early stages. Increase gradually with testing, and use conditional autonomy to trigger supervision when risks arise.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Example</div><div class="admonitionContent_BuS1"><p>A customer support agent operates autonomously for FAQs but instantly drops to Level 2 autonomy when keywords like “fraud” or “complaint” are detected.</p></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-add-human-guardrails-at-critical-points">3. Add human guardrails at critical points<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#3-add-human-guardrails-at-critical-points" class="hash-link" aria-label="Direct link to 3. Add human guardrails at critical points" title="Direct link to 3. Add human guardrails at critical points" translate="no">​</a></h4>
<p>Insert human review or approval at key steps, using parallel checks or post-action audits with reversal capability.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Example</div><div class="admonitionContent_BuS1"><p>Before issuing a provisional credit in a dispute, the agent prompts a back-office analyst for one-click approval, with justification auto-filled by the agent.</p></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-compartmentalize-roles-with-multi-agent-design">4. Compartmentalize roles with multi-agent design<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#4-compartmentalize-roles-with-multi-agent-design" class="hash-link" aria-label="Direct link to 4. Compartmentalize roles with multi-agent design" title="Direct link to 4. Compartmentalize roles with multi-agent design" translate="no">​</a></h4>
<p>Use specialized agents with limited scopes that collaborate, preventing any single agent from having unchecked end-to-end control.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Example</div><div class="admonitionContent_BuS1"><p>A service agent drafts a message, a second agent verifies it against policy, and a third agent decides if human sign-off is required before sending.</p></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-enable-manual-override-and-fallback-plans">5. Enable manual override and fallback plans<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#5-enable-manual-override-and-fallback-plans" class="hash-link" aria-label="Direct link to 5. Enable manual override and fallback plans" title="Direct link to 5. Enable manual override and fallback plans" translate="no">​</a></h4>
<p>Allow operators to halt agents instantly. Use fallback routes (e.g. human reps) and cautious rollouts like shadow mode or A/B testing.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Example</div><div class="admonitionContent_BuS1"><p>All production agents are connected to a “kill switch” dashboard with human override rights and automated routing to live reps in case of errors or latency spikes.</p></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="risk-analysis-and-failure-mode-mitigations">Risk Analysis and Failure Mode Mitigations<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#risk-analysis-and-failure-mode-mitigations" class="hash-link" aria-label="Direct link to Risk Analysis and Failure Mode Mitigations" title="Direct link to Risk Analysis and Failure Mode Mitigations" translate="no">​</a></h3>
<p>Performing a <strong>Failure Modes and Effects Analysis (FMEA)</strong> helps proactively identify weak points in AI agent design. Below are common failure modes and their corresponding mitigation strategies:</p>
<table><thead><tr><th><strong>Failure Mode</strong></th><th><strong>Description</strong></th><th><strong>Mitigation Strategy</strong></th></tr></thead><tbody><tr><td><strong>Hallucination / Misinformation</strong></td><td>LLM outputs inaccurate or misleading responses.</td><td>Add verification steps, use retrieval-augmented generation (RAG), and clearly label AI-generated content.</td></tr><tr><td><strong>Data Leakage / Privacy Breach</strong></td><td>AI exposes sensitive or personal data.</td><td>Enforce strict data controls, mask/tokenize data, limit access scope, and sanitize inputs.</td></tr><tr><td><strong>Unauthorized Action / Tool Misuse</strong></td><td>Agent takes unintended or unsafe actions.</td><td>Whitelist approved tools, sandbox execution, set transaction limits, and adversarial-test workflows.</td></tr><tr><td><strong>Coordination Failure (Multi-Agent)</strong></td><td>Agents miscommunicate or fail to synchronize tasks.</td><td>Define clear orchestration logic, add timeouts, and log inter-agent interactions for auditing.</td></tr><tr><td><strong>Model Drift / Performance Degradation</strong></td><td>Model quality decays or adapts undesirably over time.</td><td>Set up continuous monitoring, champion–challenger testing, and periodic model retraining or review.</td></tr><tr><td><strong>Security Breaches / Adversarial Attacks</strong></td><td>AI system is manipulated or exploited by external inputs.</td><td>Apply security hardening (e.g., input validation, isolation), rate-limit requests, and test adversarially.</td></tr></tbody></table>
<p>Thoughtful FMEA during agent design enables banks to embed safeguards upfront—so systems fail safely, not silently.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="illustrative-scenario-payment-dispute-resolution-workflow">Illustrative Scenario: Payment Dispute Resolution Workflow<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#illustrative-scenario-payment-dispute-resolution-workflow" class="hash-link" aria-label="Direct link to Illustrative Scenario: Payment Dispute Resolution Workflow" title="Direct link to Illustrative Scenario: Payment Dispute Resolution Workflow" translate="no">​</a></h3>
<p>This multi-agent sequence highlights role separation and escalation controls:</p>
<!-- -->
<p>Each agent operates with scoped autonomy and clear escalation paths. All actions are auditable.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="three-point-roadmap-pilot-scale-govern">Three-Point Roadmap: Pilot, Scale, Govern<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#three-point-roadmap-pilot-scale-govern" class="hash-link" aria-label="Direct link to Three-Point Roadmap: Pilot, Scale, Govern" title="Direct link to Three-Point Roadmap: Pilot, Scale, Govern" translate="no">​</a></h3>
<ol>
<li class="">
<p><strong>Short Term – Pilot Phase:</strong> Start with controlled pilots in sandbox or limited production settings. Choose valuable but not extreme-risk use cases. Keep autonomy low, require human review, and define KPIs/KRIs. Establish an AI governance committee to review pilot results.</p>
</li>
<li class="">
<p><strong>Mid Term – Scaling and Integration:</strong> After successful pilots, integrate agents with core systems and increase autonomy cautiously. Implement security, monitoring, and change-management controls, and engage regulators. Perform formal model validations or audits and define operational roles (e.g., “AI controller”).</p>
</li>
<li class="">
<p><strong>Long Term – Governance at Scale:</strong> Institutionalize AI governance like other risk domains. Implement continuous monitoring dashboards, periodic retraining and change control, external assessments/certifications, and scenario planning for worst-case AI failures. Ensure board-level visibility and embed AI risk into routine audits.</p>
</li>
</ol>
<p>By following this phased roadmap, banks can iterate and learn in the early stages and avoid reckless “big bang” deployments of unproven AI. Each phase builds the bank’s AI maturity: from gaining foundational experience, to extending capabilities, to embedding robust governance that will serve for years to come.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>Agentic AI offers retail banks powerful tools to streamline operations, personalize service, and enhance risk detection. But these benefits come with new risks. <strong>Autonomy and agency must be carefully balanced</strong>—excess in either can lead to compliance failures, customer harm, or systemic disruption.</p>
<p>Fortunately, banks aren’t starting from scratch. Research and early industry lessons offer clear strategies: define autonomy levels, apply human oversight, and build in technical safeguards. This white paper outlined a practical path forward—clarify agent roles, anticipate failures, and govern through layered controls and phased deployment.</p>
<p>In short, safe AI adoption requires control, accountability, and thoughtful design. With the right guardrails, banks can unlock the full value of AI agents—while earning the trust of regulators and customers alike.</p>
<hr>
<!-- -->
<section data-footnotes="true" class="footnotes"><h2 class="anchor anchorTargetStickyNavbar_Vzrq sr-only" id="footnote-label">Footnotes<a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#footnote-label" class="hash-link" aria-label="Direct link to Footnotes" title="Direct link to Footnotes" translate="no">​</a></h2>
<ol>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-a-6be171">
<p><a href="https://www.ciodive.com/news/ai-supervisor-role-growing-among-banks/805191/" target="_blank" rel="noopener noreferrer" class="">CIODIVE (2025). <em>Banks turn to AI supervisors as agent use surges</em> (Nov. 12, 2025).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-a-6be171" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-b-6be171">
<p><a href="https://www.consumerfinance.gov/data-research/research-reports/chatbots-in-consumer-finance/chatbots-in-consumer-finance/" target="_blank" rel="noopener noreferrer" class="">CFPB (2023). <em>Chatbots in Consumer Finance</em> (Consumer Financial Protection Bureau report, June 2023).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-b-6be171" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">↩</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-b-6be171-2" data-footnote-backref="" aria-label="Back to reference 2-2" class="data-footnote-backref">↩<sup>2</sup></a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-b-6be171-3" data-footnote-backref="" aria-label="Back to reference 2-3" class="data-footnote-backref">↩<sup>3</sup></a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-c-6be171">
<p><a href="https://www.cio.com/article/4089480/make-boards-responsible-for-ai-failures-banking-regulator-suggests.html" target="_blank" rel="noopener noreferrer" class="">Dunn, J. (2025). <em>Make boards responsible for AI failures, banking regulator suggests</em> (CIO.com, Nov 13, 2025).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-c-6be171" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref">↩</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-c-6be171-2" data-footnote-backref="" aria-label="Back to reference 3-2" class="data-footnote-backref">↩<sup>2</sup></a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-d-6be171">
<p><a href="https://arxiv.org/abs/2506.12469" target="_blank" rel="noopener noreferrer" class="">Feng et al. (2025). <em>Levels of Autonomy for AI Agents</em> (arXiv preprint 2506.12469).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-d-6be171" data-footnote-backref="" aria-label="Back to reference 4" class="data-footnote-backref">↩</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-d-6be171-2" data-footnote-backref="" aria-label="Back to reference 4-2" class="data-footnote-backref">↩<sup>2</sup></a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-d-6be171-3" data-footnote-backref="" aria-label="Back to reference 4-3" class="data-footnote-backref">↩<sup>3</sup></a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-e-6be171">
<p><a href="https://arxiv.org/abs/2509.22735" target="_blank" rel="noopener noreferrer" class="">Boddy &amp; Joseph (2025). <em>Regulating the Agency of LLM-based Agents</em> (arXiv preprint 2509.22735).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-e-6be171" data-footnote-backref="" aria-label="Back to reference 5" class="data-footnote-backref">↩</a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-g-6be171">
<p><a href="https://www.bankofengland.co.uk/report/2024/artificial-intelligence-in-uk-financial-services-2024" target="_blank" rel="noopener noreferrer" class="">Bank of England &amp; FCA (2024). <em>Artificial Intelligence in UK Financial Services</em> (Survey Report).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-g-6be171" data-footnote-backref="" aria-label="Back to reference 6" class="data-footnote-backref">↩</a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-f-6be171">
<p><a href="https://arxiv.org/abs/2502.05439" target="_blank" rel="noopener noreferrer" class="">Okpala et al. (2024). <em>Agentic AI Systems Applied to Financial Services</em> (arXiv preprint 2502.05439).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-f-6be171" data-footnote-backref="" aria-label="Back to reference 7" class="data-footnote-backref">↩</a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-h-6be171">
<p><a href="https://www.gartner.com/en/newsroom/press-releases/2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027" target="_blank" rel="noopener noreferrer" class="">Gartner (2025). <em>Press Release: Gartner Predicts Over 40% of Agentic AI Projects Will Be Canceled by 2027</em> (June 25, 2025).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-h-6be171" data-footnote-backref="" aria-label="Back to reference 8" class="data-footnote-backref">↩</a></p>
</li>
<li class="anchorTargetStickyNavbar_Vzrq" id="user-content-fn-i-6be171">
<p><a href="https://www.forbes.com/sites/brianbushard/2023/02/24/workers-chatgpt-use-restricted-at-more-banks-including-goldman-citigroup/" target="_blank" rel="noopener noreferrer" class="">Forbes (2023). <em>Workers' ChatGPT Use Restricted at More Banks</em> (reporting on banks banning employee use of ChatGPT).</a> <a href="https://lkgarcia.github.io/whitepaper/blog/balancing-autonomy-and-agency#user-content-fnref-i-6be171" data-footnote-backref="" aria-label="Back to reference 9" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section>]]></content>
        <author>
            <name>Kevin Garcia</name>
            <uri>https://github.com/lkgarcia</uri>
        </author>
        <category label="ai" term="ai"/>
        <category label="agentic-ai" term="agentic-ai"/>
        <category label="banking" term="banking"/>
        <category label="risk" term="risk"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[The AI Use Case Canvas: A Structured Framework for Evaluating and Prioritizing AI Initiatives]]></title>
        <id>https://lkgarcia.github.io/whitepaper/blog/the-ai-use-case-canvas</id>
        <link href="https://lkgarcia.github.io/whitepaper/blog/the-ai-use-case-canvas"/>
        <updated>2025-11-13T20:00:00.000Z</updated>
        <author>
            <name>Kevin Garcia</name>
            <uri>https://github.com/lkgarcia</uri>
        </author>
        <category label="ai" term="ai"/>
        <category label="agentic-ai" term="agentic-ai"/>
        <category label="banking" term="banking"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enabling Agentic AI Through Well-Defined API Contracts: Building Reliable and Scalable Toolchains]]></title>
        <id>https://lkgarcia.github.io/whitepaper/blog/enabling-agentic-ai-through-well-defined-api-contracts</id>
        <link href="https://lkgarcia.github.io/whitepaper/blog/enabling-agentic-ai-through-well-defined-api-contracts"/>
        <updated>2000-01-01T23:00:00.000Z</updated>
        <author>
            <name>Kevin Garcia</name>
            <uri>https://github.com/lkgarcia</uri>
        </author>
        <category label="ai" term="ai"/>
        <category label="agentic-ai" term="agentic-ai"/>
        <category label="banking" term="banking"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Selecting the Right AI Model: A Framework for Building Reliable and Scalable Agentic Systems]]></title>
        <id>https://lkgarcia.github.io/whitepaper/blog/selecting-the-right-ai-model</id>
        <link href="https://lkgarcia.github.io/whitepaper/blog/selecting-the-right-ai-model"/>
        <updated>2000-01-01T23:00:00.000Z</updated>
        <author>
            <name>Kevin Garcia</name>
            <uri>https://github.com/lkgarcia</uri>
        </author>
        <category label="ai" term="ai"/>
        <category label="agentic-ai" term="agentic-ai"/>
        <category label="banking" term="banking"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Agentic AI in Banking: High-Impact Use Cases and Strategic Insights for Measurable Business Value]]></title>
        <id>https://lkgarcia.github.io/whitepaper/blog/high-impact-use-cases</id>
        <link href="https://lkgarcia.github.io/whitepaper/blog/high-impact-use-cases"/>
        <updated>2000-01-01T23:00:00.000Z</updated>
        <author>
            <name>Kevin Garcia</name>
            <uri>https://github.com/lkgarcia</uri>
        </author>
        <category label="ai" term="ai"/>
        <category label="agentic-ai" term="agentic-ai"/>
        <category label="banking" term="banking"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building Enterprise AI Agents: Empowering Business Units Through Secure, Scalable, and Compliant AI Platforms]]></title>
        <id>https://lkgarcia.github.io/whitepaper/blog/building-enterprise-ai-agents</id>
        <link href="https://lkgarcia.github.io/whitepaper/blog/building-enterprise-ai-agents"/>
        <updated>2000-01-01T23:00:00.000Z</updated>
        <author>
            <name>Kevin Garcia</name>
            <uri>https://github.com/lkgarcia</uri>
        </author>
        <category label="ai" term="ai"/>
        <category label="agentic-ai" term="agentic-ai"/>
        <category label="banking" term="banking"/>
    </entry>
</feed>